{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get sen2 DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "from rasterio.merge import merge\n",
    "from rasterio.plot import show\n",
    "import rasterio.features\n",
    "import rasterio.warp\n",
    "from geojson import Point, Feature, FeatureCollection, dump\n",
    "import shapely.wkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = !pwd\n",
    "root_dir = str(root_dir[0])\n",
    "folder = \"/sen2/merged_reprojected\"\n",
    "files_folder = root_dir + folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define search criteria\n",
    "search_criteria = \"*.tif\"\n",
    "search_term = os.path.join(files_folder, search_criteria)\n",
    "# perform search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create DF and uniwe\n",
    "files = glob.glob(search_term)\n",
    "dates = []\n",
    "tiles = []\n",
    "for i in files:\n",
    "    dates.append(i[78:86])\n",
    "    tiles.append(i[102:108])\n",
    "df_sen2 = pd.DataFrame(np.column_stack([files, dates,tiles]),columns=[\"files\",\"dates\",\"tiles\"])\n",
    "unique_dates = pd.unique(df_sen2[\"dates\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sen2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "geoms = []\n",
    "out_fp = root_dir + \"footprints\"\n",
    "\n",
    "\n",
    "# Extract Footprints\n",
    "counter = 0\n",
    "for i in df_sen2[\"files\"]:\n",
    "    # def counter cond\n",
    "    counter = counter+1\n",
    "    if counter%1==0:\n",
    "        perc = 100 * float(counter)/float(len(df_sen2[\"files\"]))\n",
    "        print(str(int(perc))+\"%\",\"       \",end=\"\\r\")\n",
    "    \n",
    "    \n",
    "    file_name = i[i.rfind(\"/\")+1:i.rfind(\".\")]\n",
    "    #print(file_name)\n",
    "    out_name = out_fp + file_name+\".GeoJSON\"\n",
    "    #print(out_name)\n",
    "    \n",
    "    with rasterio.open(i) as dataset:\n",
    "\n",
    "        # Read the dataset's valid data mask as a ndarray.\n",
    "        mask = dataset.dataset_mask()\n",
    "\n",
    "        # Extract feature shapes and values from the array.\n",
    "        for geom, val in rasterio.features.shapes(\n",
    "                mask, transform=dataset.transform):\n",
    "\n",
    "            # Transform shapes from the dataset's own coordinate\n",
    "            # reference system to CRS84 (EPSG:4326).\n",
    "            #geom = rasterio.warp.transform_geom(\n",
    "            #    dataset.crs, 'EPSG:4326', geom, precision=6)\n",
    "\n",
    "            # Print GeoJSON shapes to stdout.\n",
    "            n = out_name[out_name.rfind(\"/\")+1:out_name.rfind(\".\")] + \".jp2\"\n",
    "            n = n.replace(\"footprints\",\"\")\n",
    "            names.append(n)\n",
    "            geoms.append(geom)\n",
    "print(str(100)+\"%\",\"       \",end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify WKT to be able to pass into GDF\n",
    "wkt_geoms = []\n",
    "for v,i in enumerate(geoms):\n",
    "    coordinates = i[\"coordinates\"]\n",
    "    wkt_str = \"POLYGON ((\"\n",
    "    for coor in coordinates:\n",
    "        for x in coor:\n",
    "            wkt_str=wkt_str+\"\"\n",
    "            x_1 = str(x).replace(\",\",\"\")\n",
    "            x_1 = x_1.replace(\"(\",\"\")\n",
    "            x_1 = x_1.replace(\")\",\"\")\n",
    "            #x_1 = x_1.replace(\".0\",\"\")\n",
    "            wkt_str = wkt_str+x_1+\",\"\n",
    "        wkt_str = wkt_str[:wkt_str.rfind(\",\")] + wkt_str[wkt_str.rfind(\",\")+1:]\n",
    "            \n",
    "    wkt_str = wkt_str.replace(\"[\",\"\")\n",
    "    wkt_str = wkt_str.replace(\"]\",\"\")\n",
    "    wkt_str = wkt_str+\"))\"\n",
    "    #print(wkt_str)\n",
    "    wkt_geoms.append(shapely.wkt.loads(wkt_str))\n",
    "\n",
    "df_sen2[\"geom\"] = wkt_geoms\n",
    "gdf_sen2 = gpd.GeoDataFrame(df_sen2, geometry=df_sen2.geom)\n",
    "gdf_sen2.set_crs(epsg=2154)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_sen2.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Spot6 DF\n",
    "## Get Spot6 Footprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define inputs\n",
    "sensor = \"spot6\"\n",
    "root_dir = \"/home/simon/CDE_UBS/thesis/data_collection/\"\n",
    "out_fp = root_dir + \"footprints\"\n",
    "path = root_dir + sensor\n",
    "\n",
    "\n",
    "\n",
    "# define search criteria automatically based on sensor\n",
    "if sensor == \"spot6\":\n",
    "    search_criteria = \"*.jp2\"\n",
    "if sensor == \"sen2\":\n",
    "    search_criteria = \"*.tif\"\n",
    "search_term = os.path.join(path, search_criteria)\n",
    "# perform search\n",
    "files = glob.glob(search_term)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "geoms = []\n",
    "\n",
    "# Extract Footprints\n",
    "counter = 0\n",
    "for i in files:\n",
    "    # def counter cond\n",
    "    counter = counter+1\n",
    "    if counter%1==0:\n",
    "        perc = 100 * float(counter)/float(len(files))\n",
    "        print(str(int(perc))+\"%\",\"       \",end=\"\\r\")\n",
    "    \n",
    "    \n",
    "    file_name = i[i.rfind(\"/\")+1:i.rfind(\".\")]\n",
    "    #print(file_name)\n",
    "    out_name = out_fp + file_name+\".GeoJSON\"\n",
    "    #print(out_name)\n",
    "    \n",
    "    with rasterio.open(i) as dataset:\n",
    "\n",
    "        # Read the dataset's valid data mask as a ndarray.\n",
    "        mask = dataset.dataset_mask()\n",
    "\n",
    "        # Extract feature shapes and values from the array.\n",
    "        for geom, val in rasterio.features.shapes(\n",
    "                mask, transform=dataset.transform):\n",
    "\n",
    "            # Transform shapes from the dataset's own coordinate\n",
    "            # reference system to CRS84 (EPSG:4326).\n",
    "            #geom = rasterio.warp.transform_geom(\n",
    "            #    dataset.crs, 'EPSG:4326', geom, precision=6)\n",
    "\n",
    "            # Print GeoJSON shapes to stdout.\n",
    "            n = out_name[out_name.rfind(\"/\")+1:out_name.rfind(\".\")] + \".jp2\"\n",
    "            n = n.replace(\"footprints\",\"\")\n",
    "            names.append(n)\n",
    "            geoms.append(geom)\n",
    "print(str(100)+\"%\",\"       \",end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify WKT to be able to pass into GDF\n",
    "wkt_geoms = []\n",
    "for v,i in enumerate(geoms):\n",
    "    coordinates = i[\"coordinates\"]\n",
    "    wkt_str = \"POLYGON ((\"\n",
    "    for coor in coordinates:\n",
    "        for x in coor:\n",
    "            wkt_str=wkt_str+\"\"\n",
    "            x_1 = str(x).replace(\",\",\"\")\n",
    "            x_1 = x_1.replace(\"(\",\"\")\n",
    "            x_1 = x_1.replace(\")\",\"\")\n",
    "            #x_1 = x_1.replace(\".0\",\"\")\n",
    "            wkt_str = wkt_str+x_1+\",\"\n",
    "            #print(wkt_str)\n",
    "        wkt_str = wkt_str[:wkt_str.rfind(\",\")] + wkt_str[wkt_str.rfind(\",\")+1:]\n",
    "            \n",
    "    wkt_str = wkt_str.replace(\"[\",\"\")\n",
    "    wkt_str = wkt_str.replace(\"]\",\"\")\n",
    "    wkt_str = wkt_str+\"))\"\n",
    "    #print(wkt_str)\n",
    "    wkt_geoms.append(shapely.wkt.loads(wkt_str))\n",
    "\n",
    "df_spot6 = pd.DataFrame()\n",
    "df_spot6[\"name\"] = names\n",
    "df_spot6[\"geom\"] = wkt_geoms\n",
    "gdf_spot6 = gpd.GeoDataFrame(df_spot6, geometry=df_spot6.geom)\n",
    "gdf_spot6.set_crs(epsg=2154)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_spot6.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centroid(gdf):\n",
    "    a = gpd.GeoSeries(gdf.centroid)\n",
    "    return(list(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_spot6[\"centroid\"] = get_centroid(gdf_spot6)\n",
    "gdf_sen2[\"centroid\"] = get_centroid(gdf_sen2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Spot6 positions in sen2 tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert geometryx to centroid\n",
    "gdf_spot6.set_geometry(\"centroid\",inplace=True)\n",
    "gdf_spot6.plot(markersize=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_spot6_sen2 = gdf_spot6.sjoin(gdf_sen2, how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_spot6_sen2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_spot6_sen2 = gpd.GeoDataFrame(join_spot6_sen2, geometry=\"centroid_left\")\n",
    "join_spot6_sen2.set_crs(epsg=2154,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_spot6_sen2.plot(markersize=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Spot6 Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load gdf of date info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/simon/CDE_UBS/thesis/data_collection/footprints/other/\"\n",
    "dates_spot6 = gpd.read_file(path+\"FRANCE_2018_LA93_INFO.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only dare and geometry column\n",
    "dates_spot6 = dates_spot6[[\"DATE\",\"geometry\"]]\n",
    "dates_spot6.set_crs(epsg=2154)\n",
    "dates_spot6.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_spot6.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Sen2/Spot6 Dates & Tiles with Spot6 aq. dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rop previous remenants\n",
    "join_spot6_sen2.drop('index_right', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform inner join and clean up df\n",
    "join_spot6_sen2_DATES = join_spot6_sen2.sjoin(dates_spot6, how=\"inner\")\n",
    "join_spot6_sen2_DATES.drop([\"geom_right\",\"centroid_right\",\"index_right\"], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_spot6_sen2_DATES.plot(markersize=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform back to geometry of footprint\n",
    "join_spot6_sen2_DATES = gpd.GeoDataFrame(join_spot6_sen2_DATES, geometry=\"geometry\")\n",
    "join_spot6_sen2_DATES.set_crs(epsg=2154,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_spot6_sen2_DATES.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find closest date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform dates to proper format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_sen2_date = []\n",
    "ls_spot6_date = []\n",
    "for date_s2,date_s6 in zip(join_spot6_sen2_DATES[\"dates\"],join_spot6_sen2_DATES[\"DATE\"]):\n",
    "    ls_sen2_date.append(datetime.strptime(date_s2, \"%Y%m%d\"))\n",
    "    ls_spot6_date.append(datetime.strptime(date_s6, \"%Y%m%d\"))\n",
    "join_spot6_sen2_DATES[\"date_sen2\"] = ls_sen2_date\n",
    "join_spot6_sen2_DATES[\"date_spot62\"] = ls_spot6_date\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_spot6_sen2_DATES.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform check for closest date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot6_unique = join_spot6_sen2_DATES[\"name\"].unique()\n",
    "sen2_tiles_unique = join_spot6_sen2_DATES[\"tiles\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for spot6_image in spot6_unique:\n",
    "    tmp = join_spot6_sen2_DATES[join_spot6_sen2_DATES[\"name\"] == spot6_image]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
