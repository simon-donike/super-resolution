{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from importlib import import_module\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, args, ckp):\n",
    "        super(Model, self).__init__()\n",
    "        print('Making model...')\n",
    "\n",
    "        self.scale = args.scale\n",
    "        self.idx_scale = 0\n",
    "        self.self_ensemble = args.self_ensemble\n",
    "        self.chop = args.chop\n",
    "        self.precision = args.precision\n",
    "        self.cpu = args.cpu\n",
    "        self.device = torch.device('cpu' if args.cpu else 'cuda')\n",
    "        self.n_GPUs = args.n_GPUs\n",
    "        self.save_models = args.save_models\n",
    "\n",
    "        module = import_module('model.' + args.model.lower())\n",
    "        self.model = module.make_model(args).to(self.device)\n",
    "        if args.precision == 'half': self.model.half()\n",
    "\n",
    "        if not args.cpu and args.n_GPUs > 1:\n",
    "            self.model = nn.DataParallel(self.model, range(args.n_GPUs))\n",
    "\n",
    "        self.load(\n",
    "            ckp.dir,\n",
    "            pre_train=args.pre_train,\n",
    "            resume=args.resume,\n",
    "            cpu=args.cpu\n",
    "        )\n",
    "        if args.print_model: print(self.model)\n",
    "\n",
    "    def forward(self, x, idx_scale):\n",
    "        self.idx_scale = idx_scale\n",
    "        target = self.get_model()\n",
    "        if hasattr(target, 'set_scale'):\n",
    "            target.set_scale(idx_scale)\n",
    "\n",
    "        if self.self_ensemble and not self.training:\n",
    "            if self.chop:\n",
    "                forward_function = self.forward_chop\n",
    "            else:\n",
    "                forward_function = self.model.forward\n",
    "\n",
    "            return self.forward_x8(x, forward_function)\n",
    "        elif self.chop and not self.training:\n",
    "            return self.forward_chop(x)\n",
    "        else:\n",
    "            return self.model(x)\n",
    "\n",
    "    def get_model(self):\n",
    "        if self.n_GPUs == 1:\n",
    "            return self.model\n",
    "        else:\n",
    "            return self.model.module\n",
    "\n",
    "    def state_dict(self, **kwargs):\n",
    "        target = self.get_model()\n",
    "        return target.state_dict(**kwargs)\n",
    "\n",
    "    def save(self, apath, epoch, is_best=False):\n",
    "        target = self.get_model()\n",
    "        torch.save(\n",
    "            target.state_dict(), \n",
    "            os.path.join(apath, 'model', 'model_latest.pt')\n",
    "        )\n",
    "        if is_best:\n",
    "            torch.save(\n",
    "                target.state_dict(),\n",
    "                os.path.join(apath, 'model', 'model_best.pt')\n",
    "            )\n",
    "        \n",
    "        if self.save_models:\n",
    "            torch.save(\n",
    "                target.state_dict(),\n",
    "                os.path.join(apath, 'model', 'model_{}.pt'.format(epoch))\n",
    "            )\n",
    "\n",
    "    def load(self, apath, pre_train='.', resume=-1, cpu=False):\n",
    "        if cpu:\n",
    "            kwargs = {'map_location': lambda storage, loc: storage}\n",
    "        else:\n",
    "            kwargs = {}\n",
    "\n",
    "        if resume == -1:\n",
    "            self.get_model().load_state_dict(\n",
    "                torch.load(\n",
    "                    os.path.join(apath, 'model', 'model_latest.pt'),\n",
    "                    **kwargs\n",
    "                ),\n",
    "                strict=False\n",
    "            )\n",
    "        elif resume == 0:\n",
    "            if pre_train != '.':\n",
    "                print('Loading model from {}'.format(pre_train))\n",
    "                self.get_model().load_state_dict(\n",
    "                    torch.load(pre_train, **kwargs),\n",
    "                    strict=False\n",
    "                )\n",
    "        else:\n",
    "            self.get_model().load_state_dict(\n",
    "                torch.load(\n",
    "                    os.path.join(apath, 'model', 'model_{}.pt'.format(resume)),\n",
    "                    **kwargs\n",
    "                ),\n",
    "                strict=False\n",
    "            )\n",
    "    # shave = 10, min_size=160000\n",
    "    def forward_chop(self, x, shave=10, min_size=160000):\n",
    "        scale = self.scale[self.idx_scale]\n",
    "        n_GPUs = min(self.n_GPUs, 4)\n",
    "        b, c, h, w = x.size()\n",
    "        h_half, w_half = h // 2, w // 2\n",
    "        h_size, w_size = h_half + shave, w_half + shave\n",
    "        lr_list = [\n",
    "            x[:, :, 0:h_size, 0:w_size],\n",
    "            x[:, :, 0:h_size, (w - w_size):w],\n",
    "            x[:, :, (h - h_size):h, 0:w_size],\n",
    "            x[:, :, (h - h_size):h, (w - w_size):w]]\n",
    "\n",
    "        if w_size * h_size < min_size:\n",
    "            sr_list = []\n",
    "            for i in range(0, 4, n_GPUs):\n",
    "                lr_batch = torch.cat(lr_list[i:(i + n_GPUs)], dim=0)\n",
    "                sr_batch = self.model(lr_batch)\n",
    "                sr_list.extend(sr_batch.chunk(n_GPUs, dim=0))\n",
    "        else:\n",
    "            sr_list = [\n",
    "                self.forward_chop(patch, shave=shave, min_size=min_size) \\\n",
    "                for patch in lr_list\n",
    "            ]\n",
    "\n",
    "        h, w = scale * h, scale * w\n",
    "        h_half, w_half = scale * h_half, scale * w_half\n",
    "        h_size, w_size = scale * h_size, scale * w_size\n",
    "        shave *= scale\n",
    "\n",
    "        output = x.new(b, c, h, w)\n",
    "        output[:, :, 0:h_half, 0:w_half] \\\n",
    "            = sr_list[0][:, :, 0:h_half, 0:w_half]\n",
    "        output[:, :, 0:h_half, w_half:w] \\\n",
    "            = sr_list[1][:, :, 0:h_half, (w_size - w + w_half):w_size]\n",
    "        output[:, :, h_half:h, 0:w_half] \\\n",
    "            = sr_list[2][:, :, (h_size - h + h_half):h_size, 0:w_half]\n",
    "        output[:, :, h_half:h, w_half:w] \\\n",
    "            = sr_list[3][:, :, (h_size - h + h_half):h_size, (w_size - w + w_half):w_size]\n",
    "\n",
    "        return output\n",
    "\n",
    "    def forward_x8(self, x, forward_function):\n",
    "        def _transform(v, op):\n",
    "            if self.precision != 'single': v = v.float()\n",
    "\n",
    "            v2np = v.data.cpu().numpy()\n",
    "            if op == 'v':\n",
    "                tfnp = v2np[:, :, :, ::-1].copy()\n",
    "            elif op == 'h':\n",
    "                tfnp = v2np[:, :, ::-1, :].copy()\n",
    "            elif op == 't':\n",
    "                tfnp = v2np.transpose((0, 1, 3, 2)).copy()\n",
    "\n",
    "            ret = torch.Tensor(tfnp).to(self.device)\n",
    "            if self.precision == 'half': ret = ret.half()\n",
    "\n",
    "            return ret\n",
    "\n",
    "        lr_list = [x]\n",
    "        for tf in 'v', 'h', 't':\n",
    "            lr_list.extend([_transform(t, tf) for t in lr_list])\n",
    "\n",
    "        sr_list = [forward_function(aug) for aug in lr_list]\n",
    "        for i in range(len(sr_list)):\n",
    "            if i > 3:\n",
    "                sr_list[i] = _transform(sr_list[i], 't')\n",
    "            if i % 4 > 1:\n",
    "                sr_list[i] = _transform(sr_list[i], 'h')\n",
    "            if (i % 4) % 2 == 1:\n",
    "                sr_list[i] = _transform(sr_list[i], 'v')\n",
    "\n",
    "        output_cat = torch.cat(sr_list, dim=0)\n",
    "        output = output_cat.mean(dim=0, keepdim=True)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import RCAN straight from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rcan\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define Model Args\n",
    "args = {\"n_resgroups\":3,\"n_resblocks\":3,\"n_feats\":3,\n",
    "        \"reduction\":3,\"scale\":4,\"rgb_range\":255,\"n_colors\":3,\n",
    "        \"res_scale\":3,\"data_train\":\"custom\",\n",
    "        \"rgb_mean\" :(0.4690, 0.4490, 0.4036), # TODO put actual values\n",
    "        \"rgb_range\":1, # TODO put actual range\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using custom dataset...\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Works after manipulating RCAN with hardcoded options\n",
    "\"\"\"\n",
    "model = rcan.make_model(args) # pass random number, not important anyways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    from prettytable import PrettyTable\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        param = parameter.numel()\n",
    "        table.add_row([name, param])\n",
    "        total_params+=param\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------+------------+\n",
      "|                Modules                | Parameters |\n",
      "+---------------------------------------+------------+\n",
      "|             head.0.weight             |     81     |\n",
      "|              head.0.bias              |     3      |\n",
      "|      body.0.body.0.body.0.weight      |     81     |\n",
      "|       body.0.body.0.body.0.bias       |     3      |\n",
      "|      body.0.body.0.body.2.weight      |     81     |\n",
      "|       body.0.body.0.body.2.bias       |     3      |\n",
      "| body.0.body.0.body.3.conv_du.0.weight |     9      |\n",
      "|  body.0.body.0.body.3.conv_du.0.bias  |     3      |\n",
      "| body.0.body.0.body.3.conv_du.2.weight |     9      |\n",
      "|  body.0.body.0.body.3.conv_du.2.bias  |     3      |\n",
      "|      body.0.body.1.body.0.weight      |     81     |\n",
      "|       body.0.body.1.body.0.bias       |     3      |\n",
      "|      body.0.body.1.body.2.weight      |     81     |\n",
      "|       body.0.body.1.body.2.bias       |     3      |\n",
      "| body.0.body.1.body.3.conv_du.0.weight |     9      |\n",
      "|  body.0.body.1.body.3.conv_du.0.bias  |     3      |\n",
      "| body.0.body.1.body.3.conv_du.2.weight |     9      |\n",
      "|  body.0.body.1.body.3.conv_du.2.bias  |     3      |\n",
      "|      body.0.body.2.body.0.weight      |     81     |\n",
      "|       body.0.body.2.body.0.bias       |     3      |\n",
      "|      body.0.body.2.body.2.weight      |     81     |\n",
      "|       body.0.body.2.body.2.bias       |     3      |\n",
      "| body.0.body.2.body.3.conv_du.0.weight |     9      |\n",
      "|  body.0.body.2.body.3.conv_du.0.bias  |     3      |\n",
      "| body.0.body.2.body.3.conv_du.2.weight |     9      |\n",
      "|  body.0.body.2.body.3.conv_du.2.bias  |     3      |\n",
      "|          body.0.body.3.weight         |     81     |\n",
      "|           body.0.body.3.bias          |     3      |\n",
      "|      body.1.body.0.body.0.weight      |     81     |\n",
      "|       body.1.body.0.body.0.bias       |     3      |\n",
      "|      body.1.body.0.body.2.weight      |     81     |\n",
      "|       body.1.body.0.body.2.bias       |     3      |\n",
      "| body.1.body.0.body.3.conv_du.0.weight |     9      |\n",
      "|  body.1.body.0.body.3.conv_du.0.bias  |     3      |\n",
      "| body.1.body.0.body.3.conv_du.2.weight |     9      |\n",
      "|  body.1.body.0.body.3.conv_du.2.bias  |     3      |\n",
      "|      body.1.body.1.body.0.weight      |     81     |\n",
      "|       body.1.body.1.body.0.bias       |     3      |\n",
      "|      body.1.body.1.body.2.weight      |     81     |\n",
      "|       body.1.body.1.body.2.bias       |     3      |\n",
      "| body.1.body.1.body.3.conv_du.0.weight |     9      |\n",
      "|  body.1.body.1.body.3.conv_du.0.bias  |     3      |\n",
      "| body.1.body.1.body.3.conv_du.2.weight |     9      |\n",
      "|  body.1.body.1.body.3.conv_du.2.bias  |     3      |\n",
      "|      body.1.body.2.body.0.weight      |     81     |\n",
      "|       body.1.body.2.body.0.bias       |     3      |\n",
      "|      body.1.body.2.body.2.weight      |     81     |\n",
      "|       body.1.body.2.body.2.bias       |     3      |\n",
      "| body.1.body.2.body.3.conv_du.0.weight |     9      |\n",
      "|  body.1.body.2.body.3.conv_du.0.bias  |     3      |\n",
      "| body.1.body.2.body.3.conv_du.2.weight |     9      |\n",
      "|  body.1.body.2.body.3.conv_du.2.bias  |     3      |\n",
      "|          body.1.body.3.weight         |     81     |\n",
      "|           body.1.body.3.bias          |     3      |\n",
      "|      body.2.body.0.body.0.weight      |     81     |\n",
      "|       body.2.body.0.body.0.bias       |     3      |\n",
      "|      body.2.body.0.body.2.weight      |     81     |\n",
      "|       body.2.body.0.body.2.bias       |     3      |\n",
      "| body.2.body.0.body.3.conv_du.0.weight |     9      |\n",
      "|  body.2.body.0.body.3.conv_du.0.bias  |     3      |\n",
      "| body.2.body.0.body.3.conv_du.2.weight |     9      |\n",
      "|  body.2.body.0.body.3.conv_du.2.bias  |     3      |\n",
      "|      body.2.body.1.body.0.weight      |     81     |\n",
      "|       body.2.body.1.body.0.bias       |     3      |\n",
      "|      body.2.body.1.body.2.weight      |     81     |\n",
      "|       body.2.body.1.body.2.bias       |     3      |\n",
      "| body.2.body.1.body.3.conv_du.0.weight |     9      |\n",
      "|  body.2.body.1.body.3.conv_du.0.bias  |     3      |\n",
      "| body.2.body.1.body.3.conv_du.2.weight |     9      |\n",
      "|  body.2.body.1.body.3.conv_du.2.bias  |     3      |\n",
      "|      body.2.body.2.body.0.weight      |     81     |\n",
      "|       body.2.body.2.body.0.bias       |     3      |\n",
      "|      body.2.body.2.body.2.weight      |     81     |\n",
      "|       body.2.body.2.body.2.bias       |     3      |\n",
      "| body.2.body.2.body.3.conv_du.0.weight |     9      |\n",
      "|  body.2.body.2.body.3.conv_du.0.bias  |     3      |\n",
      "| body.2.body.2.body.3.conv_du.2.weight |     9      |\n",
      "|  body.2.body.2.body.3.conv_du.2.bias  |     3      |\n",
      "|          body.2.body.3.weight         |     81     |\n",
      "|           body.2.body.3.bias          |     3      |\n",
      "|             body.3.weight             |     81     |\n",
      "|              body.3.bias              |     3      |\n",
      "|            tail.0.0.weight            |    324     |\n",
      "|             tail.0.0.bias             |     12     |\n",
      "|             tail.1.weight             |     81     |\n",
      "|              tail.1.bias              |     3      |\n",
      "+---------------------------------------+------------+\n",
      "Total Trainable Params: 2568\n"
     ]
    }
   ],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
