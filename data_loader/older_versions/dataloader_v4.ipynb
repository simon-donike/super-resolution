{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import geopandas\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import warnings\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs\n",
    "spot6_mosaic = '/home/simon/CDE_UBS/thesis/data_collection/spot6/spot6_mosaic.tif'\n",
    "spot6_path = \"/home/simon/CDE_UBS/thesis/data_collection/spot6/\"\n",
    "sen2_path = \"/home/simon/CDE_UBS/thesis/data_collection/sen2/merged_reprojected/\"\n",
    "closest_dates_filepath = \"/home/simon/CDE_UBS/thesis/data_collection/sen2/closest_dates.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define torch dataset Class\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self,spot6_mosaic,sen2_path,spot6_path,closest_dates_filepath,window_size=500,factor=(10/1.5),clip=True,temporal_images=1):\n",
    "        \n",
    "        # define raster filepath\n",
    "        self.temporal_images = temporal_images\n",
    "        self.spot6_mosaic = spot6_mosaic\n",
    "        self.sen2_path = sen2_path\n",
    "        self.spot6_path = spot6_path\n",
    "        \n",
    "        # define window size\n",
    "        self.window_size = window_size\n",
    "        self.window_size_sen2 = int(window_size/factor)\n",
    "        \n",
    "        # create list of xy coordinates spaced according to window size over raster\n",
    "        self.coordinates = Dataset.create_window_coordinates(self.spot6_mosaic,window_size=self.window_size,clip=clip)\n",
    "        \n",
    "        # get closest sen2 acq. date for each datapoint and join with info on cell types\n",
    "        self.coordinates_closest_date = Dataset.get_closest_date(self.coordinates,closest_dates_filepath)\n",
    "        \n",
    "        # test all sen2 coordinate windows for validity (warning, takes several hours!)\n",
    "        self.coordinates_closest_date_valid = Dataset.create_sen2_validity_dataframe(self.coordinates_closest_date,self.sen2_path,self.window_size_sen2)\n",
    "        # drop points where != train\n",
    "        self.coordinates_closest_date_valid = self.coordinates_closest_date_valid[self.coordinates_closest_date_valid[\"type\"]==\"train\"]\n",
    "        self.coordinates_closest_date_valid = self.coordinates_closest_date_valid.reset_index()\n",
    "        \n",
    "        # check validity for spot6\n",
    "        self.coordinates_closest_date_valid = Dataset.check_spot6_validity(self.coordinates_closest_date_valid,self.spot6_path,self.window_size)\n",
    "        \n",
    "        # reset coordinates based on manipulated coordinates datasets\n",
    "        tmp_coordinates = []\n",
    "        for x,y in zip(self.coordinates_closest_date_valid[\"x\"],self.coordinates_closest_date_valid[\"y\"]):\n",
    "            tmp_coordinates.append((x,y))\n",
    "        self.coordinates = tmp_coordinates\n",
    "        \n",
    "        print(\"\\nDataset Object successfully instanciated!\")\n",
    " \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns length of data\n",
    "        \"\"\"\n",
    "        return(len(self.coordinates_closest_date_valid))\n",
    " \n",
    "    def __getitem__(self,idx):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            - id of item\n",
    "        Output:\n",
    "            - x and y images as np arrays\n",
    "        \"\"\"\n",
    "        get_from_mosaic = False # set wether window should be taken from mosaic or individual spot6 files\n",
    "        \n",
    "        \n",
    "        import time\n",
    "        start_total = time.time()\n",
    "        \n",
    "        \n",
    "        # extract coordinates of current request\n",
    "        current_coor = self.coordinates[idx]\n",
    "        current_coor_df = self.coordinates_closest_date_valid.loc[(self.coordinates_closest_date_valid[\"x\"]==current_coor[0]) \n",
    "                                                                     & (self.coordinates_closest_date_valid[\"y\"]==current_coor[1])]\n",
    "        \n",
    "        # load spot6 window by singular image\n",
    "        if get_from_mosaic == False:\n",
    "            start_spot6 = time.time()\n",
    "            current_spot6_path = self.spot6_path + current_coor_df[\"name\"][current_coor_df.index[0]]\n",
    "            im_spot6 = Dataset.extract_spot6_window(current_spot6_path,coordinates=current_coor,window_size=self.window_size)\n",
    "            end_spot6 = time.time()\n",
    "        if get_from_mosaic == True:\n",
    "            start_spot6 = time.time()\n",
    "            im_spot6 = Dataset.extract_spot6_window(self.spot6_mosaic,coordinates=current_coor,window_size=self.window_size)\n",
    "            end_spot6 = time.time()\n",
    "        \n",
    "        start_sen2 = time.time()\n",
    "        # load sen2 window\n",
    "        current_dict = current_coor_df[\"other_valid_acq\"][current_coor_df.index[0]] # extract current dict\n",
    "        im_sen2 = Dataset.extract_sen2_window(Dataset.get_valid_sen2paths(current_dict,self.sen2_path),current_coor,self.window_size_sen2)\n",
    "        end_sen2 = time.time()\n",
    "        \n",
    "        \n",
    "        end_total = time.time()\n",
    "        #print(\"Total Time: \",end_total-start_total)\n",
    "        #print(\"Spot6 Time: \",end_spot6-start_spot6)\n",
    "        #print(\"Sen2 Time: \",end_sen2-start_sen2)\n",
    "        # return extracted images\n",
    "        \n",
    "        \n",
    "        \"\"\" CHECK FOR VALIDITY OF IMAGE SHAPES\"\"\"\n",
    "        \n",
    "        if im_spot6.shape != (3,self.window_size,self.window_size):\n",
    "            warnings.warn(\"Warning in Dataloader: SPOT6 Window shape not valid at coordinates: \"+str(current_coor)+\" - Shape: \"+str(im_spot6.shape))\n",
    "        if im_sen2.shape != (3,self.window_size_sen2,self.window_size_sen2):\n",
    "            warnings.warn(\"Warning in Dataloader: Sen-2 Window shape not valid at coordinates: \"+str(current_coor)+\" - Shape: \"+str(im_sen2.shape))\n",
    "        return(im_spot6,im_sen2)\n",
    "\n",
    "\n",
    "\n",
    "    def extract_spot6_window(filepath,coordinates,window_size=500,show=False):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            - filepath of mosaic raster\n",
    "            - point coordinates of window\n",
    "            - window size in pixels\n",
    "        Outputs:\n",
    "            - window array from input mosaic at desired location\n",
    "        \n",
    "        \"\"\"\n",
    "        import rasterio\n",
    "        import numpy as np\n",
    "\n",
    "        # if coordinates == singular tuple of coordinates, wrap it in list\n",
    "        if type(coordinates)!=list:\n",
    "            coordinates = [coordinates]\n",
    "\n",
    "        with rasterio.open(filepath) as dataset:\n",
    "            # Loop through your list of coords\n",
    "            for i, (lon, lat) in enumerate(coordinates):\n",
    "\n",
    "                # Get pixel coordinates from map coordinates\n",
    "                py, px = dataset.index(lon, lat)\n",
    "                #print('Pixel Y, X coords: {}, {}'.format(py, px))\n",
    "\n",
    "                # Build an NxN window (centered)\n",
    "                window = rasterio.windows.Window(px - window_size//2, py - window_size//2, window_size, window_size)\n",
    "                #print(window)\n",
    "\n",
    "                # Read the data in the window\n",
    "                # clip is a nbands * N * N numpy array\n",
    "                clip = dataset.read(window=window)\n",
    "\n",
    "                if show:\n",
    "                    if clip.shape == (3, window_size, window_size):\n",
    "                        image_standard_form = np.transpose(clip, (2, 1, 0))\n",
    "                        plt.imshow(image_standard_form)\n",
    "                        plt.show()\n",
    "                    else:\n",
    "                        print(\"Shape invalid - most likely edge window\")\n",
    "\n",
    "        return(clip)\n",
    "    \n",
    "    \n",
    "    def check_spot6_validity(df,spot6_path,window_size=500):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            - dataframe with coordinates, file names for spot6\n",
    "            - root path of spot6 images\n",
    "            - window size for spot6\n",
    "        Outputs:\n",
    "            - list holding True/False values\n",
    "            \"\"\"\n",
    "        print(\"\\nChecking Spot6 Validity!\")\n",
    "        try:\n",
    "            df = pd.read_pickle(\"coordinates_validity_spot6_df.pkl\")\n",
    "            print(\"Precalculated file found!\")\n",
    "        except FileNotFoundError:\n",
    "            print(\"no precalculted file found, restarting calculation. This might take several hours...\")\n",
    "            ls = []\n",
    "            counter = 0\n",
    "            for x,y,file in zip(df[\"x\"],df[\"y\"],df[\"name\"]):\n",
    "                tmp_image = extract_spot6_window(str(spot6_path+file),(x,y))\n",
    "\n",
    "                if tmp_image.shape == (3,window_size,window_size):\n",
    "                    ls.append(True)\n",
    "                else:\n",
    "                    ls.append(False)\n",
    "                counter=counter+1\n",
    "                if counter%100==0:\n",
    "                    print(\"progress: \",counter,\"/\",len(df),\"       \",end=\"\\r\")\n",
    "            print(\"Done!\\n\")\n",
    "            df[\"spot6_validity\"] = ls\n",
    "            df.to_pickle(\"coordinates_validity_spot6_df.pkl\")\n",
    "        return(df)\n",
    "    \n",
    "    \n",
    "    def create_window_coordinates(filepath,window_size=500,clip=True):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            - fiepath: path of raster that is to be loaded by window\n",
    "            - window_size: window will be pixel size NxN\n",
    "            - clip: specify if every grid point should be sampled and dropped if value is invalid\n",
    "        Outputs:\n",
    "            - list of tuple coordinates of grid points (in CRS of input raster)\n",
    "        Takes filepath, creates grid of coordinate points in wanted window size.\n",
    "        (sampling of points bc mask reads whole into RAM)\n",
    "        \"\"\"\n",
    "\n",
    "        # get bbox\n",
    "        bbox = Dataset.get_spatial_extent(filepath)\n",
    "        left = int(bbox[0])\n",
    "        bottom = int(bbox[1])\n",
    "        right = int(bbox[2])\n",
    "        top = int(bbox[3])\n",
    "\n",
    "        # iterate in N=window_size steps over image bounds, create grid\n",
    "        coor = []\n",
    "        for i in range(left,right,window_size):\n",
    "            x = i\n",
    "            for j in range(bottom,top,window_size):\n",
    "                y = j\n",
    "                coor.append((x,y))\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        PERFORM CLIP\n",
    "        \"\"\"\n",
    "        if clip:\n",
    "            import geopandas\n",
    "            import pandas as pd\n",
    "            import rasterio\n",
    "            # load into gdf\n",
    "            print(\"Performing clip of window corner points to valid raster values!\\nloading points into gdf...\")\n",
    "            df = pd.DataFrame(coor,columns=[\"x\",\"y\"])\n",
    "            gdf = geopandas.GeoDataFrame(df, geometry=geopandas.points_from_xy(df.x, df.y))\n",
    "\n",
    "            print(\"verifying points on raster...\")\n",
    "            with rasterio.open(filepath) as src:\n",
    "                gdf['value'] = [sum(x) for x in src.sample(coor)]\n",
    "\n",
    "            print(\"dropping invalid points...\")\n",
    "            # drop invalid points and useless columns\n",
    "            gdf = gdf.drop(gdf[gdf.value <= 0].index)\n",
    "            # create new list of tuples to return\n",
    "            coor = []\n",
    "            for x_,y_ in zip(gdf[\"x\"],gdf[\"y\"]):\n",
    "                coor.append((x_,y_))\n",
    "            print(\"clipping done!\\n\")\n",
    "\n",
    "        return(coor)\n",
    "\n",
    "    def get_spatial_extent(filepath):\n",
    "        \"\"\"\n",
    "        Takes filepath, returns bounding box\n",
    "        \"\"\"\n",
    "\n",
    "        import rasterio\n",
    "        with rasterio.open(filepath) as src:\n",
    "            bbox = src.bounds\n",
    "        return(bbox)\n",
    "    \n",
    "    def get_closest_date(coordinates,closest_dates_filepath):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            - coordiantes df\n",
    "            - filepath to closest dates vector\n",
    "        Outputs:\n",
    "            - joined DF of coordiantes with closest sen2 dates and paths\n",
    "        \"\"\"\n",
    "        \n",
    "        perform_train_test_split = True\n",
    "        train_test_split_filepath = \"train_test2.gpkg\"\n",
    "        \n",
    "        \n",
    "        import geopandas\n",
    "        import fiona\n",
    "        import pandas as pd\n",
    "        \n",
    "        print(\"Getting closest dates!\")\n",
    "        print(\"create closest dates gdf...\")\n",
    "        # load and transform closest dates dataframe\n",
    "        df = pd.read_pickle(closest_dates_filepath)\n",
    "        closest_dates = geopandas.GeoDataFrame(df, geometry=df.geom,crs=2154)\n",
    "        del df\n",
    "\n",
    "        print(\"create coordinates gdf...\")\n",
    "        # create coordinates gdf\n",
    "        x,y = [],[]\n",
    "        for i in coordinates:\n",
    "            x.append(i[0])\n",
    "            y.append(i[1])\n",
    "        coordinates_df = pd.DataFrame()\n",
    "        coordinates_df[\"x\"] = x\n",
    "        coordinates_df[\"y\"] = y\n",
    "        coordinates_df = geopandas.GeoDataFrame(coordinates_df, geometry=geopandas.points_from_xy(coordinates_df.x, coordinates_df.y),crs=2154)\n",
    "\n",
    "        print(\"performing spatial join...\")\n",
    "        # spatial join for coordinates\n",
    "        coordinates_joined_date = coordinates_df.sjoin(closest_dates, how=\"left\")\n",
    "        print(\"done\\n\")\n",
    "        \n",
    "        if perform_train_test_split:\n",
    "            closest_date = coordinates_joined_date # rename file\n",
    "            types = geopandas.read_file(train_test_split_filepath) # load GPKG file\n",
    "            types = types.drop_duplicates(subset=\"name\") # get rid of fuplicates\n",
    "            types = types[[\"name\",\"type\"]] # keep only relevant columns\n",
    "            coordinates_joined_date = closest_date.merge(types, on='name', how='inner', suffixes=('_1', '_2')) # join with df\n",
    "            print(\"Train-Test split integrated into dataset!\")\n",
    "        return(coordinates_joined_date)\n",
    "    \n",
    "\n",
    "    def test_sen2_window(filepath,coordinates,window_size=100,show=False):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            - filepath of mosaic raster\n",
    "            - point coordinates of window\n",
    "            - window size in pixels\n",
    "        Outputs:\n",
    "            - window array from input mosaic at desired location\n",
    "        \"\"\"\n",
    "\n",
    "        import rasterio\n",
    "        import numpy as np\n",
    "\n",
    "        # if coordinates == singular tuple of coordinates, wrap it in list\n",
    "        if type(coordinates)!=list:\n",
    "            coordinates = [coordinates]\n",
    "\n",
    "        with rasterio.open(filepath) as dataset:\n",
    "            # Loop through your list of coords\n",
    "            for i, (lon, lat) in enumerate(coordinates):\n",
    "\n",
    "              # Get pixel coordinates from map coordinates\n",
    "                py, px = dataset.index(lon, lat)\n",
    "                #print('Pixel Y, X coords: {}, {}'.format(py, px))\n",
    "\n",
    "                # Build an NxN window (centered)\n",
    "                window = rasterio.windows.Window(px - window_size//2, py - window_size//2, window_size, window_size)\n",
    "                #print(window)\n",
    "\n",
    "                # Read the data in the window\n",
    "                # clip is a nbands * N * N numpy array\n",
    "                clip = dataset.read(window=window)\n",
    "\n",
    "                if clip.shape == (3, window_size, window_size) and np.average(clip)>0.1:\n",
    "                    validity = True\n",
    "\n",
    "                    if show: # show image\n",
    "                        image_standard_form = np.transpose(clip, (2, 1, 0))\n",
    "                        #print(type(image_standard_form))\n",
    "                        plt.imshow(image_standard_form)\n",
    "                        plt.show()\n",
    "                else:\n",
    "                    validity = False\n",
    "\n",
    "        return(validity)\n",
    "    \n",
    "    \n",
    "    def create_sen2_validity_dataframe(df,sen2_path,window_size_sen2):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            - dataframe of coordinate points incl. Sen2 info\n",
    "            - path to sen2 files\n",
    "        Outputs:\n",
    "            - DF w/ Sen3 dict appended with calidity information\n",
    "            \"\"\"\n",
    "        print(\"\\nChecking Sen2 validity for all windows & acquisitions - might take several hours\")\n",
    "        \n",
    "        \n",
    "        def test_sen2_window(filepath,coordinates,window_size,show=False): # inner function\n",
    "            \"\"\"\n",
    "            Inputs:\n",
    "                - filepath of mosaic raster\n",
    "                - point coordinates of window\n",
    "                - window size in pixels\n",
    "            Outputs:\n",
    "                - window array from input mosaic at desired location\n",
    "            \"\"\"\n",
    "\n",
    "            import rasterio\n",
    "            import numpy as np\n",
    "\n",
    "            # if coordinates == singular tuple of coordinates, wrap it in list\n",
    "            if type(coordinates)!=list:\n",
    "                coordinates = [coordinates]\n",
    "\n",
    "            with rasterio.open(filepath) as dataset:\n",
    "                # Loop through your list of coords\n",
    "                for i, (lon, lat) in enumerate(coordinates):\n",
    "\n",
    "                  # Get pixel coordinates from map coordinates\n",
    "                    py, px = dataset.index(lon, lat)\n",
    "                    #print('Pixel Y, X coords: {}, {}'.format(py, px))\n",
    "\n",
    "                    # Build an NxN window (centered)\n",
    "                    window = rasterio.windows.Window(px - window_size//2, py - window_size//2, window_size, window_size)\n",
    "                    #print(window)\n",
    "\n",
    "                    # Read the data in the window\n",
    "                    # clip is a nbands * N * N numpy array\n",
    "                    clip = dataset.read(window=window)\n",
    "\n",
    "                    if clip.shape == (3, window_size, window_size) and np.average(clip)>0.1:\n",
    "                        validity = True\n",
    "\n",
    "                        if show: # show image\n",
    "                            image_standard_form = np.transpose(clip, (2, 1, 0))\n",
    "                            #print(type(image_standard_form))\n",
    "                            plt.imshow(image_standard_form)\n",
    "                            plt.show()\n",
    "                    else:\n",
    "                        validity = False\n",
    "\n",
    "            return(validity)\n",
    "            # END INNER FUNCTION\n",
    "        \n",
    "        \n",
    "        \n",
    "        # try to read precalculated file, if not recalculating\n",
    "        try:\n",
    "            df = pd.read_pickle(\"coordinates_validity_df.pkl\")\n",
    "            print(\"Precalculated File found - no recalculation necessary!\")\n",
    "            return(df)\n",
    "        except FileNotFoundError:\n",
    "            print(\"No precalculated file found, calculating valid sen2 patches... for the moment for 3 valid image patches\")\n",
    "        \n",
    "        \n",
    "        count=0\n",
    "        ls_dict = []\n",
    "        df_copy = df.copy(deep=True) # copy in order to not affect original file\n",
    "        # iterate over rows in original df: dict of acq., x and y\n",
    "        for dic,x,y in zip(df_copy[\"other_acq\"],df_copy[\"x\"],df_copy[\"y\"]):\n",
    "            dic_copy = copy.deepcopy(dic)\n",
    "            dic_keys = dic.keys() # extract keys ergo acquisitions \n",
    "            dic_keys = list(dic_keys) # turn to list\n",
    "            dic_keys.sort() # order list\n",
    "            \n",
    "            #print(x,y,dic_keys)\n",
    "            \n",
    "            # iterate over other acquisition date \n",
    "            counter_validity = 0 # counter that counts how many valid images were found yet\n",
    "            for i in dic_keys:\n",
    "                file = dic[i][1] # extract file name\n",
    "                filepath = sen2_path+file # save filepath\n",
    "                \n",
    "                if counter_validity<=3:\n",
    "                    temp_res = test_sen2_window(filepath,(x,y),window_size_sen2,show=False) # check validity\n",
    "                    \n",
    "                    if temp_res==True:\n",
    "                        counter_validity = counter_validity+1\n",
    "                        dic_copy[i].append(temp_res)\n",
    "                    if temp_res==False:\n",
    "                        dic_copy[i].append(False)\n",
    "                \n",
    "                if counter_validity>3: # if 3 valid reached, append False to further dates\n",
    "                    dic_copy[i].append(False)\n",
    "                \n",
    "                #if dic_copy[i][-1] != temp_res: # append only if information isn't present yet\n",
    "                #    dic_copy[i].append(temp_res)\n",
    "\n",
    "            ls_dict.append(dic_copy) # append list w/ validity info to list which will be in DF\n",
    "\n",
    "            count=count+1\n",
    "            if count%100==0:\n",
    "                perc = round(100 * float(count)/float(len(df)),2)\n",
    "                print(str(perc),\"%   \",end=\"\\r\")\n",
    "\n",
    "        df[\"other_valid_acq\"]=ls_dict\n",
    "        df.to_pickle(\"coordinates_validity_df.pkl\")\n",
    "        return(df)\n",
    "    \n",
    "    def get_valid_sen2paths(acq_dict_sen2,path,num_images=1):\n",
    "        dates = list(acq_dict_sen2.keys()) # get keys ergo closest times\n",
    "        dates.sort() # sort so lowest can be accessed\n",
    "\n",
    "        valid_files = []\n",
    "        count=0\n",
    "        count_true = 0\n",
    "        for v,i in enumerate(dates): # iterate over closest\n",
    "            if count_true==num_images: # stop while loop if number of required images is extracted\n",
    "                #print(\"all extracted\")\n",
    "                break\n",
    "\n",
    "            if acq_dict_sen2[i][2]==True:\n",
    "                count_true=count_true+1\n",
    "                filepath = acq_dict_sen2[i][1]\n",
    "                valid_files.append(filepath)\n",
    "\n",
    "            # protection for if more images requested than available\n",
    "            if v==len(dates)-1:\n",
    "                warnings.warn(\"WARNING: More image aqc. dates requested than available. Recalculate full validity dataframe or request fewer sen2 images!\")\n",
    "                break\n",
    "\n",
    "        for v,i in enumerate(valid_files):\n",
    "            valid_files[v] = path + valid_files[v]\n",
    "        return(valid_files)\n",
    "    \n",
    "    def extract_sen2_window(path_list,coordinates,window_size):\n",
    "        import rasterio\n",
    "        import numpy as np\n",
    "        show=False # Show result?\n",
    "\n",
    "        # extract coordinates\n",
    "        lon,lat = coordinates[0],coordinates[1]\n",
    "        # loop over list of acq.\n",
    "        for file_path in path_list:\n",
    "            # open file\n",
    "            with rasterio.open(file_path) as dataset:\n",
    "                # get pixel coordinates\n",
    "                py,px = dataset.index(lon, lat)\n",
    "                # build and read window\n",
    "                window = rasterio.windows.Window(px - window_size//2, py - window_size//2, window_size, window_size)\n",
    "                clip = dataset.read(window=window)\n",
    "\n",
    "                # if wanted, show image\n",
    "                if show:\n",
    "                        if clip.shape == (3, window_size, window_size):\n",
    "                            image_standard_form = np.transpose(clip, (2, 1, 0))\n",
    "                            plt.imshow(image_standard_form)\n",
    "                            plt.show()\n",
    "                        else:\n",
    "                            print(\"Shape invalid - most likely edge window\")\n",
    "        return(clip)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing clip of window corner points to valid raster values!\n",
      "loading points into gdf...\n",
      "verifying points on raster...\n",
      "dropping invalid points...\n",
      "clipping done!\n",
      "\n",
      "Getting closest dates!\n",
      "create closest dates gdf...\n",
      "create coordinates gdf...\n",
      "performing spatial join...\n",
      "done\n",
      "\n",
      "Train-Test split integrated into dataset!\n",
      "\n",
      "Checking Sen2 validity for all windows & acquisitions - might take several hours\n",
      "Precalculated File found - no recalculation necessary!\n",
      "\n",
      "Checking Spot6 Validity!\n",
      "no precalculted file found, restarting calculation. This might take several hours...\n",
      "progress:  1400 / 133102        \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-55568effc50e>\u001b[0m in \u001b[0;36mcheck_spot6_validity\u001b[0;34m(df, spot6_path, window_size)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"coordinates_validity_spot6_df.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Precalculated file found!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     ) as handles:\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    710\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'coordinates_validity_spot6_df.pkl'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-3edbd6806dfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Instanciate dataset object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspot6_mosaic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msen2_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mspot6_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclosest_dates_filepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-51-55568effc50e>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, spot6_mosaic, sen2_path, spot6_path, closest_dates_filepath, window_size, factor, clip, temporal_images)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# check validity for spot6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoordinates_closest_date_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_spot6_validity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoordinates_closest_date_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspot6_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# reset coordinates based on manipulated coordinates datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-55568effc50e>\u001b[0m in \u001b[0;36mcheck_spot6_validity\u001b[0;34m(df, spot6_path, window_size)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m                 \u001b[0mtmp_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_spot6_window\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspot6_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtmp_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-98df3d27aa88>\u001b[0m in \u001b[0;36mextract_spot6_window\u001b[0;34m(filepath, coordinates, window_size, show)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;31m# Read the data in the window\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;31m# clip is a nbands * N * N numpy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Instanciate dataset object\n",
    "dataset = Dataset(spot6_mosaic,sen2_path,spot6_path,closest_dates_filepath,window_size=500,factor=(10/1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loader Length:  133102\n"
     ]
    }
   ],
   "source": [
    "# Instanciate dataloader object\n",
    "loader = DataLoader(dataset,batch_size=1, shuffle=True, num_workers=1)\n",
    "print(\"Loader Length: \",len(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.7/site-packages/ipykernel_launcher.py:88: UserWarning: Warning in Dataloader: SPOT6 Window shape not valid at coordinates: (129000, 6835000) - Shape: (3, 500, 250)\n"
     ]
    }
   ],
   "source": [
    "a,b = dataset.__getitem__(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def plot_images(a,b,title):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    from torchvision.transforms import ToPILImage\n",
    "    \n",
    "\n",
    "    a = np.transpose(a,(1,2,0))\n",
    "    b = np.transpose(b,(1,2,0))\n",
    "    b = img.numpy()\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2,figsize=(10,5))\n",
    "    fig.suptitle('Spot6 vs Sen2 - time to fetch: '+str(title))\n",
    "    ax1.imshow(a)\n",
    "    ax2.imshow(b)\n",
    "    plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(0,10):\\n    start=time.time()\\n    #a,b = dataset.__getitem__(random.randint(0,len(dataset)))\\n    _ = next(iter(loader))\\n    a,b = _[0],_[1]\\n    end=time.time()\\n    \\n    plot_images(a,b,round(end-start,3))\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for i in range(0,10):\n",
    "    start=time.time()\n",
    "    #a,b = dataset.__getitem__(random.randint(0,len(dataset)))\n",
    "    _ = next(iter(loader))\n",
    "    a,b = _[0],_[1]\n",
    "    end=time.time()\n",
    "    \n",
    "    plot_images(a,b,round(end-start,3))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for i in range(0,20):\n",
    "    start = time.time()\n",
    "    a,b = dataset.__getitem__(random.randint(0,len(loader)))\n",
    "    end = time.time()\n",
    "    print(\"Elapsed time: \",round(end-start,3))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
