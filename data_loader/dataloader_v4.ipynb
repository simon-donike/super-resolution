{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import geopandas\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs\n",
    "spot6_mosaic = '/home/simon/CDE_UBS/thesis/data_collection/spot6/spot6_mosaic.tif'\n",
    "spot6_path = \"/home/simon/CDE_UBS/thesis/data_collection/spot6/\"\n",
    "sen2_path = \"/home/simon/CDE_UBS/thesis/data_collection/sen2/merged_reprojected/\"\n",
    "closest_dates_filepath = \"/home/simon/CDE_UBS/thesis/data_collection/sen2/closest_dates.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define torch dataset Class\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self,spot6_mosaic,sen2_path,spot6_path,closest_dates_filepath,window_size=500,factor=(10/1.5),clip=True,temporal_images=1):\n",
    "        \n",
    "        # define raster filepath\n",
    "        self.temporal_images = temporal_images\n",
    "        self.spot6_mosaic = spot6_mosaic\n",
    "        self.sen2_path = sen2_path\n",
    "        self.spot6_path = spot6_path\n",
    "        \n",
    "        # define window size\n",
    "        self.window_size = window_size\n",
    "        self.window_size_sen2 = int(window_size/factor)\n",
    "        \n",
    "        # create list of xy coordinates spaced according to window size over raster\n",
    "        self.coordinates = Dataset.create_window_coordinates(self.spot6_mosaic,window_size=self.window_size,clip=clip)\n",
    "        \n",
    "        # get closest sen2 acq. date for each datapoint and join with info on cell types\n",
    "        self.coordinates_closest_date = Dataset.get_closest_date(self.coordinates,closest_dates_filepath)\n",
    "        \n",
    "        # test all sen2 coordinate windows for validity (warning, takes several hours!)\n",
    "        self.coordinates_closest_date_valid = Dataset.create_sen2_validity_dataframe(self.coordinates_closest_date,self.sen2_path,self.window_size_sen2) # [25000:25500]\n",
    "        \n",
    "        print(\"\\nDataset Object successfully instanciated!\")\n",
    " \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns length of data\n",
    "        \"\"\"\n",
    "        return(len(self.coordinates))\n",
    " \n",
    "    def __getitem__(self,idx):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            - id of item\n",
    "        Output:\n",
    "            - x and y images as np arrays\n",
    "        \"\"\"\n",
    "        import time\n",
    "        start_total = time.time()\n",
    "        \n",
    "        \n",
    "        # extract coordinates of current request\n",
    "        current_coor = self.coordinates[idx]\n",
    "        current_coor_df = self.coordinates_closest_date_valid.loc[(self.coordinates_closest_date_valid[\"x\"]==current_coor[0]) \n",
    "                                                                     & (self.coordinates_closest_date_valid[\"y\"]==current_coor[1])]\n",
    "        \n",
    "        # load spot6 window by singular image\n",
    "        start_spot6 = time.time()\n",
    "        current_spot6_path = self.spot6_path + current_coor_df[\"name\"][current_coor_df.index[0]]\n",
    "        im_spot6 = Dataset.extract_spot6_window(current_spot6_path,coordinates=current_coor,window_size=self.window_size)\n",
    "        end_spot6 = time.time()\n",
    "        \n",
    "        start_sen2 = time.time()\n",
    "        # load sen2 window\n",
    "        current_dict = current_coor_df[\"other_valid_acq\"][current_coor_df.index[0]] # extract current dict\n",
    "        im_sen2 = Dataset.extract_sen2_window(Dataset.get_valid_sen2paths(current_dict,self.sen2_path),current_coor,self.window_size_sen2)\n",
    "        end_sen2 = time.time()\n",
    "        \n",
    "        \n",
    "        end_total = time.time()\n",
    "        #print(\"Total Time: \",end_total-start_total)\n",
    "        #print(\"Spot6 Time: \",end_spot6-start_spot6)\n",
    "        #print(\"Sen2 Time: \",end_sen2-start_sen2)\n",
    "        # return extracted images\n",
    "        return(im_spot6,im_sen2)\n",
    "\n",
    "\n",
    "\n",
    "    def extract_spot6_window(filepath,coordinates,window_size=500,show=False):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            - filepath of mosaic raster\n",
    "            - point coordinates of window\n",
    "            - window size in pixels\n",
    "        Outputs:\n",
    "            - window array from input mosaic at desired location\n",
    "        \n",
    "        \"\"\"\n",
    "        import rasterio\n",
    "        import numpy as np\n",
    "\n",
    "        # if coordinates == singular tuple of coordinates, wrap it in list\n",
    "        if type(coordinates)!=list:\n",
    "            coordinates = [coordinates]\n",
    "\n",
    "        with rasterio.open(filepath) as dataset:\n",
    "            # Loop through your list of coords\n",
    "            for i, (lon, lat) in enumerate(coordinates):\n",
    "\n",
    "                # Get pixel coordinates from map coordinates\n",
    "                py, px = dataset.index(lon, lat)\n",
    "                #print('Pixel Y, X coords: {}, {}'.format(py, px))\n",
    "\n",
    "                # Build an NxN window (centered)\n",
    "                window = rasterio.windows.Window(px - window_size//2, py - window_size//2, window_size, window_size)\n",
    "                #print(window)\n",
    "\n",
    "                # Read the data in the window\n",
    "                # clip is a nbands * N * N numpy array\n",
    "                clip = dataset.read(window=window)\n",
    "\n",
    "                if show:\n",
    "                    if clip.shape == (3, window_size, window_size):\n",
    "                        image_standard_form = np.transpose(clip, (2, 1, 0))\n",
    "                        plt.imshow(image_standard_form)\n",
    "                        plt.show()\n",
    "                    else:\n",
    "                        print(\"Shape invalid - most likely edge window\")\n",
    "\n",
    "        return(clip)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def create_window_coordinates(filepath,window_size=500,clip=True):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            - fiepath: path of raster that is to be loaded by window\n",
    "            - window_size: window will be pixel size NxN\n",
    "            - clip: specify if every grid point should be sampled and dropped if value is invalid\n",
    "        Outputs:\n",
    "            - list of tuple coordinates of grid points (in CRS of input raster)\n",
    "        Takes filepath, creates grid of coordinate points in wanted window size.\n",
    "        (sampling of points bc mask reads whole into RAM)\n",
    "        \"\"\"\n",
    "\n",
    "        # get bbox\n",
    "        bbox = Dataset.get_spatial_extent(filepath)\n",
    "        left = int(bbox[0])\n",
    "        bottom = int(bbox[1])\n",
    "        right = int(bbox[2])\n",
    "        top = int(bbox[3])\n",
    "\n",
    "        # iterate in N=window_size steps over image bounds, create grid\n",
    "        coor = []\n",
    "        for i in range(left,right,window_size):\n",
    "            x = i\n",
    "            for j in range(bottom,top,window_size):\n",
    "                y = j\n",
    "                coor.append((x,y))\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        PERFORM CLIP\n",
    "        \"\"\"\n",
    "        if clip:\n",
    "            import geopandas\n",
    "            import pandas as pd\n",
    "            import rasterio\n",
    "            # load into gdf\n",
    "            print(\"Performing clip of window corner points to valid raster values!\\nloading points into gdf...\")\n",
    "            df = pd.DataFrame(coor,columns=[\"x\",\"y\"])\n",
    "            gdf = geopandas.GeoDataFrame(df, geometry=geopandas.points_from_xy(df.x, df.y))\n",
    "\n",
    "            print(\"verifying points on raster...\")\n",
    "            with rasterio.open(filepath) as src:\n",
    "                gdf['value'] = [sum(x) for x in src.sample(coor)]\n",
    "\n",
    "            print(\"dropping invalid points...\")\n",
    "            # drop invalid points and useless columns\n",
    "            gdf = gdf.drop(gdf[gdf.value <= 0].index)\n",
    "            # create new list of tuples to return\n",
    "            coor = []\n",
    "            for x_,y_ in zip(gdf[\"x\"],gdf[\"y\"]):\n",
    "                coor.append((x_,y_))\n",
    "            print(\"clipping done!\\n\")\n",
    "\n",
    "        return(coor)\n",
    "\n",
    "    def get_spatial_extent(filepath):\n",
    "        \"\"\"\n",
    "        Takes filepath, returns bounding box\n",
    "        \"\"\"\n",
    "\n",
    "        import rasterio\n",
    "        with rasterio.open(filepath) as src:\n",
    "            bbox = src.bounds\n",
    "        return(bbox)\n",
    "    \n",
    "    def get_closest_date(coordinates,closest_dates_filepath):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            - coordiantes df\n",
    "            - filepath to closest dates vector\n",
    "        Outputs:\n",
    "            - joined DF of coordiantes with closest sen2 dates and paths\n",
    "        \"\"\"\n",
    "        \n",
    "        perform_train_test_split = True\n",
    "        train_test_split_filepath = \"train_test2.gpkg\"\n",
    "        \n",
    "        \n",
    "        import geopandas\n",
    "        import fiona\n",
    "        import pandas as pd\n",
    "        \n",
    "        print(\"Getting closest dates!\")\n",
    "        print(\"create closest dates gdf...\")\n",
    "        # load and transform closest dates dataframe\n",
    "        df = pd.read_pickle(closest_dates_filepath)\n",
    "        closest_dates = geopandas.GeoDataFrame(df, geometry=df.geom,crs=2154)\n",
    "        del df\n",
    "\n",
    "        print(\"create coordinates gdf...\")\n",
    "        # create coordinates gdf\n",
    "        x,y = [],[]\n",
    "        for i in coordinates:\n",
    "            x.append(i[0])\n",
    "            y.append(i[1])\n",
    "        coordinates_df = pd.DataFrame()\n",
    "        coordinates_df[\"x\"] = x\n",
    "        coordinates_df[\"y\"] = y\n",
    "        coordinates_df = geopandas.GeoDataFrame(coordinates_df, geometry=geopandas.points_from_xy(coordinates_df.x, coordinates_df.y),crs=2154)\n",
    "\n",
    "        print(\"performing spatial join...\")\n",
    "        # spatial join for coordinates\n",
    "        coordinates_joined_date = coordinates_df.sjoin(closest_dates, how=\"left\")\n",
    "        print(\"done\\n\")\n",
    "        \n",
    "        if perform_train_test_split:\n",
    "            closest_date = coordinates_joined_date # rename file\n",
    "            types = geopandas.read_file(train_test_split_filepath) # load GPKG file\n",
    "            types = types.drop_duplicates(subset=\"name\") # get rid of fuplicates\n",
    "            types = types[[\"name\",\"type\"]] # keep only relevant columns\n",
    "            coordinates_joined_date = closest_date.merge(types, on='name', how='inner', suffixes=('_1', '_2')) # join with df\n",
    "            print(\"Train-Test split integrated into dataset!\")\n",
    "        return(coordinates_joined_date)\n",
    "    \n",
    "\n",
    "    def test_sen2_window(filepath,coordinates,window_size=100,show=False):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            - filepath of mosaic raster\n",
    "            - point coordinates of window\n",
    "            - window size in pixels\n",
    "        Outputs:\n",
    "            - window array from input mosaic at desired location\n",
    "        \"\"\"\n",
    "\n",
    "        import rasterio\n",
    "        import numpy as np\n",
    "\n",
    "        # if coordinates == singular tuple of coordinates, wrap it in list\n",
    "        if type(coordinates)!=list:\n",
    "            coordinates = [coordinates]\n",
    "\n",
    "        with rasterio.open(filepath) as dataset:\n",
    "            # Loop through your list of coords\n",
    "            for i, (lon, lat) in enumerate(coordinates):\n",
    "\n",
    "              # Get pixel coordinates from map coordinates\n",
    "                py, px = dataset.index(lon, lat)\n",
    "                #print('Pixel Y, X coords: {}, {}'.format(py, px))\n",
    "\n",
    "                # Build an NxN window (centered)\n",
    "                window = rasterio.windows.Window(px - window_size//2, py - window_size//2, window_size, window_size)\n",
    "                #print(window)\n",
    "\n",
    "                # Read the data in the window\n",
    "                # clip is a nbands * N * N numpy array\n",
    "                clip = dataset.read(window=window)\n",
    "\n",
    "                if clip.shape == (3, window_size, window_size) and np.average(clip)>0.1:\n",
    "                    validity = True\n",
    "\n",
    "                    if show: # show image\n",
    "                        image_standard_form = np.transpose(clip, (2, 1, 0))\n",
    "                        #print(type(image_standard_form))\n",
    "                        plt.imshow(image_standard_form)\n",
    "                        plt.show()\n",
    "                else:\n",
    "                    validity = False\n",
    "\n",
    "        return(validity)\n",
    "    \n",
    "    \n",
    "    def create_sen2_validity_dataframe(df,sen2_path,window_size_sen2=75):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            - dataframe of coordinate points incl. Sen2 info\n",
    "            - path to sen2 files\n",
    "        Outputs:\n",
    "            - DF w/ Sen3 dict appended with calidity information\n",
    "            \"\"\"\n",
    "        print(\"\\nChecking Sen2 validity for all windows & acquisitions - might take several hours\")\n",
    "        \n",
    "        \n",
    "        def test_sen2_window(filepath,coordinates,window_size=75,show=False): # inner function\n",
    "            \"\"\"\n",
    "            Inputs:\n",
    "                - filepath of mosaic raster\n",
    "                - point coordinates of window\n",
    "                - window size in pixels\n",
    "            Outputs:\n",
    "                - window array from input mosaic at desired location\n",
    "            \"\"\"\n",
    "\n",
    "            import rasterio\n",
    "            import numpy as np\n",
    "\n",
    "            # if coordinates == singular tuple of coordinates, wrap it in list\n",
    "            if type(coordinates)!=list:\n",
    "                coordinates = [coordinates]\n",
    "\n",
    "            with rasterio.open(filepath) as dataset:\n",
    "                # Loop through your list of coords\n",
    "                for i, (lon, lat) in enumerate(coordinates):\n",
    "\n",
    "                  # Get pixel coordinates from map coordinates\n",
    "                    py, px = dataset.index(lon, lat)\n",
    "                    #print('Pixel Y, X coords: {}, {}'.format(py, px))\n",
    "\n",
    "                    # Build an NxN window (centered)\n",
    "                    window = rasterio.windows.Window(px - window_size//2, py - window_size//2, window_size, window_size)\n",
    "                    #print(window)\n",
    "\n",
    "                    # Read the data in the window\n",
    "                    # clip is a nbands * N * N numpy array\n",
    "                    clip = dataset.read(window=window)\n",
    "\n",
    "                    if clip.shape == (3, window_size, window_size) and np.average(clip)>0.1:\n",
    "                        validity = True\n",
    "\n",
    "                        if show: # show image\n",
    "                            image_standard_form = np.transpose(clip, (2, 1, 0))\n",
    "                            #print(type(image_standard_form))\n",
    "                            plt.imshow(image_standard_form)\n",
    "                            plt.show()\n",
    "                    else:\n",
    "                        validity = False\n",
    "\n",
    "            return(validity)\n",
    "            # END INNER FUNCTION\n",
    "        \n",
    "        \n",
    "        \n",
    "        # try to read precalculated file, if not recalculating\n",
    "        try:\n",
    "            df = pd.read_pickle(\"coordinates_validity_df.pkl\")\n",
    "            print(\"Precalculated File found - no recalculation necessary!\")\n",
    "            return(df)\n",
    "        except FileNotFoundError:\n",
    "            print(\"No precalculated file found, calculating valid sen2 patches... for the moment for 3 valid image patches\")\n",
    "        \n",
    "        \n",
    "        count=0\n",
    "        ls_dict = []\n",
    "        df_copy = df.copy(deep=True) # copy in order to not affect original file\n",
    "        # iterate over rows in original df: dict of acq., x and y\n",
    "        for dic,x,y in zip(df_copy[\"other_acq\"],df_copy[\"x\"],df_copy[\"y\"]):\n",
    "            dic_copy = copy.deepcopy(dic)\n",
    "            dic_keys = dic.keys() # extract keys ergo acquisitions \n",
    "            dic_keys = list(dic_keys) # turn to list\n",
    "            dic_keys.sort() # order list\n",
    "            \n",
    "            #print(x,y,dic_keys)\n",
    "            \n",
    "            # iterate over other acquisition date \n",
    "            counter_validity = 0 # counter that counts how many valid images were found yet\n",
    "            for i in dic_keys:\n",
    "                file = dic[i][1] # extract file name\n",
    "                filepath = sen2_path+file # save filepath\n",
    "                \n",
    "                if counter_validity<=3:\n",
    "                    temp_res = test_sen2_window(filepath,(x,y),window_size=window_size_sen2,show=False) # check validity\n",
    "                    \n",
    "                    if temp_res==True:\n",
    "                        counter_validity = counter_validity+1\n",
    "                        dic_copy[i].append(temp_res)\n",
    "                    if temp_res==False:\n",
    "                        dic_copy[i].append(False)\n",
    "                \n",
    "                if counter_validity>3: # if 3 valid reached, append False to further dates\n",
    "                    dic_copy[i].append(False)\n",
    "                \n",
    "                #if dic_copy[i][-1] != temp_res: # append only if information isn't present yet\n",
    "                #    dic_copy[i].append(temp_res)\n",
    "\n",
    "            ls_dict.append(dic_copy) # append list w/ validity info to list which will be in DF\n",
    "\n",
    "            count=count+1\n",
    "            if count%100==0:\n",
    "                perc = round(100 * float(count)/float(len(df)),2)\n",
    "                print(str(perc),\"%   \",end=\"\\r\")\n",
    "\n",
    "        df[\"other_valid_acq\"]=ls_dict\n",
    "        df.to_pickle(\"coordinates_validity_df.pkl\")\n",
    "        return(df)\n",
    "    \n",
    "    def get_valid_sen2paths(acq_dict_sen2,path,num_images=1):\n",
    "        dates = list(acq_dict_sen2.keys()) # get keys ergo closest times\n",
    "        dates.sort() # sort so lowest can be accessed\n",
    "\n",
    "        valid_files = []\n",
    "        count=0\n",
    "        count_true = 0\n",
    "        for v,i in enumerate(dates): # iterate over closest\n",
    "            if count_true==num_images: # stop while loop if number of required images is extracted\n",
    "                #print(\"all extracted\")\n",
    "                break\n",
    "\n",
    "            if acq_dict_sen2[i][2]==True:\n",
    "                count_true=count_true+1\n",
    "                filepath = acq_dict_sen2[i][1]\n",
    "                valid_files.append(filepath)\n",
    "\n",
    "            # protection for if more images requested than available\n",
    "            if v==len(dates)-1:\n",
    "                print(\"WARNING: More image aqc. dates requested than available. This will cause problems!\")\n",
    "                break\n",
    "\n",
    "        for v,i in enumerate(valid_files):\n",
    "            valid_files[v] = path + valid_files[v]\n",
    "        return(valid_files)\n",
    "    \n",
    "    def extract_sen2_window(path_list,coordinates,window_size=75):\n",
    "        import rasterio\n",
    "        import numpy as np\n",
    "        show=False # Show result?\n",
    "\n",
    "        # extract coordinates\n",
    "        lon,lat = coordinates[0],coordinates[1]\n",
    "        # loop over list of acq.\n",
    "        for file_path in path_list:\n",
    "            # open file\n",
    "            with rasterio.open(file_path) as dataset:\n",
    "                # get pixel coordinates\n",
    "                py,px = dataset.index(lon, lat)\n",
    "                # build and read window\n",
    "                window = rasterio.windows.Window(px - window_size//2, py - window_size//2, window_size, window_size)\n",
    "                clip = dataset.read(window=window)\n",
    "\n",
    "                # if wanted, show image\n",
    "                if show:\n",
    "                        if clip.shape == (3, window_size, window_size):\n",
    "                            image_standard_form = np.transpose(clip, (2, 1, 0))\n",
    "                            plt.imshow(image_standard_form)\n",
    "                            plt.show()\n",
    "                        else:\n",
    "                            print(\"Shape invalid - most likely edge window\")\n",
    "        return(clip)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing clip of window corner points to valid raster values!\n",
      "loading points into gdf...\n",
      "verifying points on raster...\n",
      "dropping invalid points...\n",
      "clipping done!\n",
      "\n",
      "Getting closest dates!\n",
      "create closest dates gdf...\n",
      "create coordinates gdf...\n",
      "performing spatial join...\n",
      "done\n",
      "\n",
      "Train-Test split integrated into dataset!\n",
      "\n",
      "Checking Sen2 validity for all windows & acquisitions - might take several hours\n",
      "Precalculated File found - no recalculation necessary!\n",
      "\n",
      "Dataset Object successfully instanciated!\n"
     ]
    }
   ],
   "source": [
    "# Instanciate dataset object\n",
    "dataset = Dataset(spot6_mosaic,sen2_path,spot6_path,closest_dates_filepath,window_size=500,factor=(10/1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loader Length:  60304\n"
     ]
    }
   ],
   "source": [
    "# Instanciate dataloader object\n",
    "loader = DataLoader(dataset,batch_size=2, shuffle=True, num_workers=1)\n",
    "print(\"Loader Length: \",len(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size: 1   Workers: 1   time per it: 1.754\n",
      "Batch Size: 2   Workers: 2   time per it: 2.579\n",
      "Batch Size: 3   Workers: 3   time per it: 3.413\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for i in [(1,1),(2,2),(3,3)]:\n",
    "    \n",
    "    b,w = int(i[0]),int(i[1])\n",
    "    loader = DataLoader(dataset,batch_size=b, shuffle=False, num_workers=w)\n",
    "    start = time.time()\n",
    "    _,_ = next(iter(loader))\n",
    "    end = time.time()\n",
    "    \n",
    "    print(\"Batch Size:\",b,\"  Workers:\",w,\"  time per it:\",round(end-start,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.85 s ± 116 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "loader = DataLoader(dataset,batch_size=1, shuffle=False, num_workers=1)\n",
    "a,b = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "loader = DataLoader(dataset,batch_size=2, shuffle=False, num_workers=1)\n",
    "a,b = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "loader = DataLoader(dataset,batch_size=2, shuffle=False, num_workers=2)\n",
    "a,b = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "loader = DataLoader(dataset,batch_size=5, shuffle=False, num_workers=5,prefetch_factor=1)\n",
    "a,b = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "loader = DataLoader(dataset,batch_size=5, shuffle=False, num_workers=5,prefetch_factor=5)\n",
    "a,b = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
