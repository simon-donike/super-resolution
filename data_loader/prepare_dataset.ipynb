{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define torch dataset Class\n",
    "def prepare_dataset(spot6_mosaic,sen2_path,spot6_path,closest_dates_filepath,window_size=500,factor=(10/1.5),clip=True,temporal_images=1):\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import random\n",
    "    import geopandas\n",
    "    import copy\n",
    "    import numpy as np\n",
    "\n",
    "    import warnings\n",
    "    import random\n",
    "    import time\n",
    "    \n",
    "    def extract_spot6_window(filepath,coordinates,window_size=500,show=False):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            - filepath of mosaic raster\n",
    "            - point coordinates of window\n",
    "            - window size in pixels\n",
    "        Outputs:\n",
    "            - window array from input mosaic at desired location\n",
    "        \n",
    "        \"\"\"\n",
    "        import rasterio\n",
    "        import numpy as np\n",
    "\n",
    "        # if coordinates == singular tuple of coordinates, wrap it in list\n",
    "        if type(coordinates)!=list:\n",
    "            coordinates = [coordinates]\n",
    "\n",
    "        with rasterio.open(filepath) as dataset:\n",
    "            # Loop through your list of coords\n",
    "            for i, (lon, lat) in enumerate(coordinates):\n",
    "\n",
    "                # Get pixel coordinates from map coordinates\n",
    "                py, px = dataset.index(lon, lat)\n",
    "                #print('Pixel Y, X coords: {}, {}'.format(py, px))\n",
    "\n",
    "                # Build an NxN window (centered)\n",
    "                window = rasterio.windows.Window(px - window_size//2, py - window_size//2, window_size, window_size)\n",
    "                #print(window)\n",
    "\n",
    "                # Read the data in the window\n",
    "                # clip is a nbands * N * N numpy array\n",
    "                clip = dataset.read(window=window)\n",
    "\n",
    "                if show:\n",
    "                    if clip.shape == (3, window_size, window_size):\n",
    "                        image_standard_form = np.transpose(clip, (2, 1, 0))\n",
    "                        plt.imshow(image_standard_form)\n",
    "                        plt.show()\n",
    "                    else:\n",
    "                        print(\"Shape invalid - most likely edge window\")\n",
    "\n",
    "        return(clip)\n",
    "    \n",
    "    \n",
    "    def check_spot6_validity(df,spot6_path,window_size=500):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            - dataframe with coordinates, file names for spot6\n",
    "            - root path of spot6 images\n",
    "            - window size for spot6\n",
    "        Outputs:\n",
    "            - list holding True/False values\n",
    "            \"\"\"\n",
    "        print(\"\\nChecking Spot6 Validity!\")\n",
    "        try:\n",
    "            df = pd.read_pickle(\"coordinates_validity_spot6_df.pkl\")\n",
    "            print(\"Precalculated file found!\")\n",
    "        except FileNotFoundError:\n",
    "            print(\"no precalculted file found, restarting calculation. This might take several hours...\")\n",
    "            ls = []\n",
    "            counter = 0\n",
    "            for x,y,file in zip(df[\"x\"],df[\"y\"],df[\"name\"]):\n",
    "                \n",
    "                try:\n",
    "                    tmp_image = extract_spot6_window(str(spot6_path+file),(x,y))\n",
    "\n",
    "                    if tmp_image.shape == (3,window_size,window_size):\n",
    "                        ls.append(True)\n",
    "                    else:\n",
    "                        ls.append(False)\n",
    "                    counter=counter+1\n",
    "                except:\n",
    "                    ls.append(False)\n",
    "                    warnings.warn(\"Exception in Spot6 Val. Check! For file: \"+str(file))\n",
    "                \n",
    "                \n",
    "                if counter%100==0:\n",
    "                    perc = (100/len(df)) * counter\n",
    "                    print(\"progress: \",round(perc,2),\"%       \",end=\"\\r\")\n",
    "            print(\"Done!\\n\")\n",
    "            df[\"spot6_validity\"] = ls\n",
    "            df.to_pickle(\"coordinates_validity_spot6_df.pkl\")\n",
    "        return(df)\n",
    "    \n",
    "    \n",
    "    def create_window_coordinates(filepath,window_size=500,clip=True):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            - fiepath: path of raster that is to be loaded by window\n",
    "            - window_size: window will be pixel size NxN\n",
    "            - clip: specify if every grid point should be sampled and dropped if value is invalid\n",
    "        Outputs:\n",
    "            - list of tuple coordinates of grid points (in CRS of input raster)\n",
    "        Takes filepath, creates grid of coordinate points in wanted window size.\n",
    "        (sampling of points bc mask reads whole into RAM)\n",
    "        \"\"\"\n",
    "\n",
    "        # get bbox\n",
    "        bbox = get_spatial_extent(filepath)\n",
    "        left = int(bbox[0])\n",
    "        bottom = int(bbox[1])\n",
    "        right = int(bbox[2])\n",
    "        top = int(bbox[3])\n",
    "\n",
    "        # iterate in N=window_size steps over image bounds, create grid\n",
    "        coor = []\n",
    "        for i in range(left,right,window_size):\n",
    "            x = i\n",
    "            for j in range(bottom,top,window_size):\n",
    "                y = j\n",
    "                coor.append((x,y))\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        PERFORM CLIP\n",
    "        \"\"\"\n",
    "        if clip:\n",
    "            import geopandas\n",
    "            import pandas as pd\n",
    "            import rasterio\n",
    "            # load into gdf\n",
    "            print(\"Performing clip of window corner points to valid raster values!\\nloading points into gdf...\")\n",
    "            df = pd.DataFrame(coor,columns=[\"x\",\"y\"])\n",
    "            gdf = geopandas.GeoDataFrame(df, geometry=geopandas.points_from_xy(df.x, df.y))\n",
    "\n",
    "            print(\"verifying points on raster...\")\n",
    "            with rasterio.open(filepath) as src:\n",
    "                gdf['value'] = [sum(x) for x in src.sample(coor)]\n",
    "\n",
    "            print(\"dropping invalid points...\")\n",
    "            # drop invalid points and useless columns\n",
    "            gdf = gdf.drop(gdf[gdf.value <= 0].index)\n",
    "            # create new list of tuples to return\n",
    "            coor = []\n",
    "            for x_,y_ in zip(gdf[\"x\"],gdf[\"y\"]):\n",
    "                coor.append((x_,y_))\n",
    "            print(\"clipping done!                        \\n\")\n",
    "\n",
    "        return(coor)\n",
    "\n",
    "    def get_spatial_extent(filepath):\n",
    "        \"\"\"\n",
    "        Takes filepath, returns bounding box\n",
    "        \"\"\"\n",
    "\n",
    "        import rasterio\n",
    "        with rasterio.open(filepath) as src:\n",
    "            bbox = src.bounds\n",
    "        return(bbox)\n",
    "    \n",
    "    def get_closest_date(coordinates,closest_dates_filepath):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            - coordiantes df\n",
    "            - filepath to closest dates vector\n",
    "        Outputs:\n",
    "            - joined DF of coordiantes with closest sen2 dates and paths\n",
    "        \"\"\"\n",
    "        \n",
    "        perform_train_test_split = True\n",
    "        train_test_split_filepath = \"train_test2.gpkg\"\n",
    "        \n",
    "        \n",
    "        import geopandas\n",
    "        import fiona\n",
    "        import pandas as pd\n",
    "        \n",
    "        print(\"Getting closest dates!\")\n",
    "        print(\"create closest dates gdf...\")\n",
    "        # load and transform closest dates dataframe\n",
    "        df = pd.read_pickle(closest_dates_filepath)\n",
    "        closest_dates = geopandas.GeoDataFrame(df, geometry=df.geom,crs=2154)\n",
    "        del df\n",
    "\n",
    "        print(\"create coordinates gdf...\")\n",
    "        # create coordinates gdf\n",
    "        x,y = [],[]\n",
    "        for i in coordinates:\n",
    "            x.append(i[0])\n",
    "            y.append(i[1])\n",
    "        coordinates_df = pd.DataFrame()\n",
    "        coordinates_df[\"x\"] = x\n",
    "        coordinates_df[\"y\"] = y\n",
    "        coordinates_df = geopandas.GeoDataFrame(coordinates_df, geometry=geopandas.points_from_xy(coordinates_df.x, coordinates_df.y),crs=2154)\n",
    "\n",
    "        print(\"performing spatial join...\")\n",
    "        # spatial join for coordinates\n",
    "        coordinates_joined_date = coordinates_df.sjoin(closest_dates, how=\"left\")\n",
    "        print(\"done\\n\")\n",
    "        \n",
    "        if perform_train_test_split:\n",
    "            closest_date = coordinates_joined_date # rename file\n",
    "            types = geopandas.read_file(train_test_split_filepath) # load GPKG file\n",
    "            types = types.drop_duplicates(subset=\"name\") # get rid of fuplicates\n",
    "            types = types[[\"name\",\"type\"]] # keep only relevant columns\n",
    "            coordinates_joined_date = closest_date.merge(types, on='name', how='inner', suffixes=('_1', '_2')) # join with df\n",
    "            print(\"Train-Test split integrated into dataset!\")\n",
    "        return(coordinates_joined_date)\n",
    "    \n",
    "\n",
    "    def test_sen2_window(filepath,coordinates,window_size=100,show=False):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            - filepath of mosaic raster\n",
    "            - point coordinates of window\n",
    "            - window size in pixels\n",
    "        Outputs:\n",
    "            - window array from input mosaic at desired location\n",
    "        \"\"\"\n",
    "\n",
    "        import rasterio\n",
    "        import numpy as np\n",
    "\n",
    "        # if coordinates == singular tuple of coordinates, wrap it in list\n",
    "        if type(coordinates)!=list:\n",
    "            coordinates = [coordinates]\n",
    "\n",
    "        with rasterio.open(filepath) as dataset:\n",
    "            # Loop through your list of coords\n",
    "            for i, (lon, lat) in enumerate(coordinates):\n",
    "\n",
    "              # Get pixel coordinates from map coordinates\n",
    "                py, px = dataset.index(lon, lat)\n",
    "                #print('Pixel Y, X coords: {}, {}'.format(py, px))\n",
    "\n",
    "                # Build an NxN window (centered)\n",
    "                window = rasterio.windows.Window(px - window_size//2, py - window_size//2, window_size, window_size)\n",
    "                #print(window)\n",
    "\n",
    "                # Read the data in the window\n",
    "                # clip is a nbands * N * N numpy array\n",
    "                clip = dataset.read(window=window)\n",
    "\n",
    "                if clip.shape == (3, window_size, window_size) and np.average(clip)>0.1:\n",
    "                    validity = True\n",
    "\n",
    "                    if show: # show image\n",
    "                        image_standard_form = np.transpose(clip, (2, 1, 0))\n",
    "                        #print(type(image_standard_form))\n",
    "                        plt.imshow(image_standard_form)\n",
    "                        plt.show()\n",
    "                else:\n",
    "                    validity = False\n",
    "\n",
    "        return(validity)\n",
    "    \n",
    "    \n",
    "    def create_sen2_validity_dataframe(df,sen2_path,window_size_sen2):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            - dataframe of coordinate points incl. Sen2 info\n",
    "            - path to sen2 files\n",
    "        Outputs:\n",
    "            - DF w/ Sen3 dict appended with calidity information\n",
    "            \"\"\"\n",
    "        print(\"\\nChecking Sen2 validity for all windows & acquisitions - might take several hours\")\n",
    "        \n",
    "        \n",
    "        def test_sen2_window(filepath,coordinates,window_size,show=False): # inner function\n",
    "            \"\"\"\n",
    "            Inputs:\n",
    "                - filepath of mosaic raster\n",
    "                - point coordinates of window\n",
    "                - window size in pixels\n",
    "            Outputs:\n",
    "                - window array from input mosaic at desired location\n",
    "            \"\"\"\n",
    "\n",
    "            import rasterio\n",
    "            import numpy as np\n",
    "\n",
    "            # if coordinates == singular tuple of coordinates, wrap it in list\n",
    "            if type(coordinates)!=list:\n",
    "                coordinates = [coordinates]\n",
    "\n",
    "            with rasterio.open(filepath) as dataset:\n",
    "                # Loop through your list of coords\n",
    "                for i, (lon, lat) in enumerate(coordinates):\n",
    "\n",
    "                  # Get pixel coordinates from map coordinates\n",
    "                    py, px = dataset.index(lon, lat)\n",
    "                    #print('Pixel Y, X coords: {}, {}'.format(py, px))\n",
    "\n",
    "                    # Build an NxN window (centered)\n",
    "                    window = rasterio.windows.Window(px - window_size//2, py - window_size//2, window_size, window_size)\n",
    "                    #print(window)\n",
    "\n",
    "                    # Read the data in the window\n",
    "                    # clip is a nbands * N * N numpy array\n",
    "                    clip = dataset.read(window=window)\n",
    "\n",
    "                    if clip.shape == (3, window_size, window_size) and np.average(clip)>0.1:\n",
    "                        validity = True\n",
    "\n",
    "                        if show: # show image\n",
    "                            image_standard_form = np.transpose(clip, (2, 1, 0))\n",
    "                            #print(type(image_standard_form))\n",
    "                            plt.imshow(image_standard_form)\n",
    "                            plt.show()\n",
    "                    else:\n",
    "                        validity = False\n",
    "\n",
    "            return(validity)\n",
    "            # END INNER FUNCTION\n",
    "        \n",
    "        \n",
    "        \n",
    "        # try to read precalculated file, if not recalculating\n",
    "        try:\n",
    "            df = pd.read_pickle(\"coordinates_validity_sen2_df.pkl\")\n",
    "            print(\"Precalculated File found - no recalculation necessary!\")\n",
    "            return(df)\n",
    "        except FileNotFoundError:\n",
    "            print(\"No precalculated file found, calculating valid sen2 patches... for the moment for 3 valid image patches\")\n",
    "        \n",
    "        \n",
    "        count=0\n",
    "        ls_dict = []\n",
    "        df_copy = df.copy(deep=True) # copy in order to not affect original file\n",
    "        # iterate over rows in original df: dict of acq., x and y\n",
    "        for dic,x,y in zip(df_copy[\"other_acq\"],df_copy[\"x\"],df_copy[\"y\"]):\n",
    "            dic_copy = copy.deepcopy(dic)\n",
    "            dic_keys = dic.keys() # extract keys ergo acquisitions \n",
    "            dic_keys = list(dic_keys) # turn to list\n",
    "            dic_keys.sort() # order list\n",
    "            \n",
    "            #print(x,y,dic_keys)\n",
    "            \n",
    "            # iterate over other acquisition date \n",
    "            counter_validity = 0 # counter that counts how many valid images were found yet\n",
    "            for i in dic_keys:\n",
    "                file = dic[i][1] # extract file name\n",
    "                filepath = sen2_path+file # save filepath\n",
    "                \n",
    "                if counter_validity<=3:\n",
    "                    temp_res = test_sen2_window(filepath,(x,y),window_size_sen2,show=False) # check validity\n",
    "                    \n",
    "                    if temp_res==True:\n",
    "                        counter_validity = counter_validity+1\n",
    "                        dic_copy[i].append(temp_res)\n",
    "                    if temp_res==False:\n",
    "                        dic_copy[i].append(False)\n",
    "                \n",
    "                if counter_validity>3: # if 3 valid reached, append False to further dates\n",
    "                    dic_copy[i].append(False)\n",
    "                \n",
    "                #if dic_copy[i][-1] != temp_res: # append only if information isn't present yet\n",
    "                #    dic_copy[i].append(temp_res)\n",
    "\n",
    "            ls_dict.append(dic_copy) # append list w/ validity info to list which will be in DF\n",
    "\n",
    "            count=count+1\n",
    "            if count%100==0:\n",
    "                perc = round(100 * float(count)/float(len(df)),2)\n",
    "                print(str(perc),\"%   \",end=\"\\r\")\n",
    "\n",
    "        df[\"other_valid_acq\"]=ls_dict\n",
    "        df.to_pickle(\"coordinates_validity_sen2_df.pkl\")\n",
    "        return(df)\n",
    "    \n",
    "    \n",
    "    def extract_sen2_window(path_list,coordinates,window_size):\n",
    "        import rasterio\n",
    "        import numpy as np\n",
    "        show=False # Show result?\n",
    "\n",
    "        # extract coordinates\n",
    "        lon,lat = coordinates[0],coordinates[1]\n",
    "        # loop over list of acq.\n",
    "        for file_path in path_list:\n",
    "            # open file\n",
    "            with rasterio.open(file_path) as dataset:\n",
    "                # get pixel coordinates\n",
    "                py,px = dataset.index(lon, lat)\n",
    "                # build and read window\n",
    "                window = rasterio.windows.Window(px - window_size//2, py - window_size//2, window_size, window_size)\n",
    "                clip = dataset.read(window=window)\n",
    "\n",
    "                # if wanted, show image\n",
    "                if show:\n",
    "                        if clip.shape == (3, window_size, window_size):\n",
    "                            image_standard_form = np.transpose(clip, (2, 1, 0))\n",
    "                            plt.imshow(image_standard_form)\n",
    "                            plt.show()\n",
    "                        else:\n",
    "                            print(\"Shape invalid - most likely edge window\")\n",
    "        return(clip)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    CALLING FUNCTIONS\n",
    "    \"\"\"\n",
    "    # try to read precalculated dataset\n",
    "    try:\n",
    "        coordinates_closest_date_valid = pd.read_pickle(\"final_dataset.pkl\")\n",
    "        print(\"Fully computed dataset found, no calculations necesary!\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Full dataset not found, recalculating from scratch. This might take up to 12 hrs, depending on the availability of the Sen2/Spot6 validity files.\\n\\n\")\n",
    "        # define raster filepath\n",
    "        temporal_images = temporal_images\n",
    "        spot6_mosaic = spot6_mosaic\n",
    "        sen2_path = sen2_path\n",
    "        spot6_path = spot6_path\n",
    "\n",
    "        # define window size\n",
    "        window_size = window_size\n",
    "        window_size_sen2 = int(window_size/factor)\n",
    "\n",
    "        # create list of xy coordinates spaced according to window size over raster\n",
    "        coordinates = create_window_coordinates(spot6_mosaic,window_size=window_size,clip=clip)\n",
    "\n",
    "        # get closest sen2 acq. date for each datapoint and join with info on cell types\n",
    "        coordinates_closest_date = get_closest_date(coordinates,closest_dates_filepath)\n",
    "\n",
    "        # test all sen2 coordinate windows for validity (warning, takes several hours!)\n",
    "        coordinates_closest_date_valid = create_sen2_validity_dataframe(coordinates_closest_date,sen2_path,window_size_sen2)\n",
    "        # drop points where != train\n",
    "        coordinates_closest_date_valid = coordinates_closest_date_valid[coordinates_closest_date_valid[\"type\"]==\"train\"]\n",
    "        \n",
    "\n",
    "        # check validity for spot6\n",
    "        coordinates_closest_date_valid = check_spot6_validity(coordinates_closest_date_valid,spot6_path,window_size)\n",
    "\n",
    "        # reset coordinates based on manipulated coordinates datasets, reset index\n",
    "        coordinates_closest_date_valid = coordinates_closest_date_valid.reset_index()\n",
    "        tmp_coordinates = []\n",
    "        for x,y in zip(coordinates_closest_date_valid[\"x\"],coordinates_closest_date_valid[\"y\"]):\n",
    "            tmp_coordinates.append((x,y))\n",
    "        coordinates = tmp_coordinates\n",
    "        coordinates_closest_date_valid.to_pickle(\"final_dataset.pkl\")\n",
    "        \n",
    "    print(\"\\nDataset successfully prepared!\")\n",
    "    \n",
    "    return(coordinates_closest_date_valid)\n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs\n",
    "spot6_mosaic = '/home/simon/CDE_UBS/thesis/data_collection/spot6/spot6_mosaic.tif'\n",
    "spot6_path = \"/home/simon/CDE_UBS/thesis/data_collection/spot6/\"\n",
    "sen2_path = \"/home/simon/CDE_UBS/thesis/data_collection/sen2/merged_reprojected/\"\n",
    "closest_dates_filepath = \"/home/simon/CDE_UBS/thesis/data_loader/data/closest_dates.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fully computed dataset found, no calculations necesary!\n",
      "\n",
      "Dataset successfully prepared!\n"
     ]
    }
   ],
   "source": [
    "__ = prepare_dataset(spot6_mosaic,sen2_path,spot6_path,closest_dates_filepath,window_size=500,factor=(10/1.5),clip=True,temporal_images=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>geometry</th>\n",
       "      <th>index_right</th>\n",
       "      <th>name</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>other_acq</th>\n",
       "      <th>geom</th>\n",
       "      <th>type</th>\n",
       "      <th>other_valid_acq</th>\n",
       "      <th>spot6_validity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1026</td>\n",
       "      <td>126000</td>\n",
       "      <td>6840000</td>\n",
       "      <td>POINT (126000.000 6840000.000)</td>\n",
       "      <td>1979</td>\n",
       "      <td>ORT_2018_0126_6843_LA93_8Bits.jp2</td>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "      <td>{33: [2018-04-03 00:00:00, 'SENTINEL2A_2018040...</td>\n",
       "      <td>POLYGON ((126000.000 6843000.000, 126000.000 6...</td>\n",
       "      <td>train</td>\n",
       "      <td>{33: [2018-04-03 00:00:00, 'SENTINEL2A_2018040...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1027</td>\n",
       "      <td>126000</td>\n",
       "      <td>6840500</td>\n",
       "      <td>POINT (126000.000 6840500.000)</td>\n",
       "      <td>1979</td>\n",
       "      <td>ORT_2018_0126_6843_LA93_8Bits.jp2</td>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "      <td>{33: [2018-04-03 00:00:00, 'SENTINEL2A_2018040...</td>\n",
       "      <td>POLYGON ((126000.000 6843000.000, 126000.000 6...</td>\n",
       "      <td>train</td>\n",
       "      <td>{33: [2018-04-03 00:00:00, 'SENTINEL2A_2018040...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1028</td>\n",
       "      <td>126000</td>\n",
       "      <td>6841000</td>\n",
       "      <td>POINT (126000.000 6841000.000)</td>\n",
       "      <td>1979</td>\n",
       "      <td>ORT_2018_0126_6843_LA93_8Bits.jp2</td>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "      <td>{33: [2018-04-03 00:00:00, 'SENTINEL2A_2018040...</td>\n",
       "      <td>POLYGON ((126000.000 6843000.000, 126000.000 6...</td>\n",
       "      <td>train</td>\n",
       "      <td>{33: [2018-04-03 00:00:00, 'SENTINEL2A_2018040...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1029</td>\n",
       "      <td>126000</td>\n",
       "      <td>6841500</td>\n",
       "      <td>POINT (126000.000 6841500.000)</td>\n",
       "      <td>1979</td>\n",
       "      <td>ORT_2018_0126_6843_LA93_8Bits.jp2</td>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "      <td>{33: [2018-04-03 00:00:00, 'SENTINEL2A_2018040...</td>\n",
       "      <td>POLYGON ((126000.000 6843000.000, 126000.000 6...</td>\n",
       "      <td>train</td>\n",
       "      <td>{33: [2018-04-03 00:00:00, 'SENTINEL2A_2018040...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1030</td>\n",
       "      <td>126000</td>\n",
       "      <td>6842000</td>\n",
       "      <td>POINT (126000.000 6842000.000)</td>\n",
       "      <td>1979</td>\n",
       "      <td>ORT_2018_0126_6843_LA93_8Bits.jp2</td>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "      <td>{33: [2018-04-03 00:00:00, 'SENTINEL2A_2018040...</td>\n",
       "      <td>POLYGON ((126000.000 6843000.000, 126000.000 6...</td>\n",
       "      <td>train</td>\n",
       "      <td>{33: [2018-04-03 00:00:00, 'SENTINEL2A_2018040...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133097</th>\n",
       "      <td>162530</td>\n",
       "      <td>401500</td>\n",
       "      <td>6829000</td>\n",
       "      <td>POINT (401500.000 6829000.000)</td>\n",
       "      <td>3334</td>\n",
       "      <td>ORT_2018_0399_6831_LA93_8Bits.jp2</td>\n",
       "      <td>1</td>\n",
       "      <td>159</td>\n",
       "      <td>{159: [2018-09-26 00:00:00, 'SENTINEL2B_201809...</td>\n",
       "      <td>POLYGON ((399000.000 6831000.000, 399000.000 6...</td>\n",
       "      <td>train</td>\n",
       "      <td>{159: [2018-09-26 00:00:00, 'SENTINEL2B_201809...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133098</th>\n",
       "      <td>162531</td>\n",
       "      <td>401500</td>\n",
       "      <td>6829500</td>\n",
       "      <td>POINT (401500.000 6829500.000)</td>\n",
       "      <td>3334</td>\n",
       "      <td>ORT_2018_0399_6831_LA93_8Bits.jp2</td>\n",
       "      <td>1</td>\n",
       "      <td>159</td>\n",
       "      <td>{159: [2018-09-26 00:00:00, 'SENTINEL2B_201809...</td>\n",
       "      <td>POLYGON ((399000.000 6831000.000, 399000.000 6...</td>\n",
       "      <td>train</td>\n",
       "      <td>{159: [2018-09-26 00:00:00, 'SENTINEL2B_201809...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133099</th>\n",
       "      <td>162532</td>\n",
       "      <td>401500</td>\n",
       "      <td>6830000</td>\n",
       "      <td>POINT (401500.000 6830000.000)</td>\n",
       "      <td>3334</td>\n",
       "      <td>ORT_2018_0399_6831_LA93_8Bits.jp2</td>\n",
       "      <td>1</td>\n",
       "      <td>159</td>\n",
       "      <td>{159: [2018-09-26 00:00:00, 'SENTINEL2B_201809...</td>\n",
       "      <td>POLYGON ((399000.000 6831000.000, 399000.000 6...</td>\n",
       "      <td>train</td>\n",
       "      <td>{159: [2018-09-26 00:00:00, 'SENTINEL2B_201809...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133100</th>\n",
       "      <td>162533</td>\n",
       "      <td>401500</td>\n",
       "      <td>6830500</td>\n",
       "      <td>POINT (401500.000 6830500.000)</td>\n",
       "      <td>3334</td>\n",
       "      <td>ORT_2018_0399_6831_LA93_8Bits.jp2</td>\n",
       "      <td>1</td>\n",
       "      <td>159</td>\n",
       "      <td>{159: [2018-09-26 00:00:00, 'SENTINEL2B_201809...</td>\n",
       "      <td>POLYGON ((399000.000 6831000.000, 399000.000 6...</td>\n",
       "      <td>train</td>\n",
       "      <td>{159: [2018-09-26 00:00:00, 'SENTINEL2B_201809...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133101</th>\n",
       "      <td>162534</td>\n",
       "      <td>401500</td>\n",
       "      <td>6831000</td>\n",
       "      <td>POINT (401500.000 6831000.000)</td>\n",
       "      <td>3334</td>\n",
       "      <td>ORT_2018_0399_6831_LA93_8Bits.jp2</td>\n",
       "      <td>1</td>\n",
       "      <td>159</td>\n",
       "      <td>{159: [2018-09-26 00:00:00, 'SENTINEL2B_201809...</td>\n",
       "      <td>POLYGON ((399000.000 6831000.000, 399000.000 6...</td>\n",
       "      <td>train</td>\n",
       "      <td>{159: [2018-09-26 00:00:00, 'SENTINEL2B_201809...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>133102 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index       x        y                        geometry  index_right  \\\n",
       "0         1026  126000  6840000  POINT (126000.000 6840000.000)         1979   \n",
       "1         1027  126000  6840500  POINT (126000.000 6840500.000)         1979   \n",
       "2         1028  126000  6841000  POINT (126000.000 6841000.000)         1979   \n",
       "3         1029  126000  6841500  POINT (126000.000 6841500.000)         1979   \n",
       "4         1030  126000  6842000  POINT (126000.000 6842000.000)         1979   \n",
       "...        ...     ...      ...                             ...          ...   \n",
       "133097  162530  401500  6829000  POINT (401500.000 6829000.000)         3334   \n",
       "133098  162531  401500  6829500  POINT (401500.000 6829500.000)         3334   \n",
       "133099  162532  401500  6830000  POINT (401500.000 6830000.000)         3334   \n",
       "133100  162533  401500  6830500  POINT (401500.000 6830500.000)         3334   \n",
       "133101  162534  401500  6831000  POINT (401500.000 6831000.000)         3334   \n",
       "\n",
       "                                     name  min  max  \\\n",
       "0       ORT_2018_0126_6843_LA93_8Bits.jp2    1  144   \n",
       "1       ORT_2018_0126_6843_LA93_8Bits.jp2    1  144   \n",
       "2       ORT_2018_0126_6843_LA93_8Bits.jp2    1  144   \n",
       "3       ORT_2018_0126_6843_LA93_8Bits.jp2    1  144   \n",
       "4       ORT_2018_0126_6843_LA93_8Bits.jp2    1  144   \n",
       "...                                   ...  ...  ...   \n",
       "133097  ORT_2018_0399_6831_LA93_8Bits.jp2    1  159   \n",
       "133098  ORT_2018_0399_6831_LA93_8Bits.jp2    1  159   \n",
       "133099  ORT_2018_0399_6831_LA93_8Bits.jp2    1  159   \n",
       "133100  ORT_2018_0399_6831_LA93_8Bits.jp2    1  159   \n",
       "133101  ORT_2018_0399_6831_LA93_8Bits.jp2    1  159   \n",
       "\n",
       "                                                other_acq  \\\n",
       "0       {33: [2018-04-03 00:00:00, 'SENTINEL2A_2018040...   \n",
       "1       {33: [2018-04-03 00:00:00, 'SENTINEL2A_2018040...   \n",
       "2       {33: [2018-04-03 00:00:00, 'SENTINEL2A_2018040...   \n",
       "3       {33: [2018-04-03 00:00:00, 'SENTINEL2A_2018040...   \n",
       "4       {33: [2018-04-03 00:00:00, 'SENTINEL2A_2018040...   \n",
       "...                                                   ...   \n",
       "133097  {159: [2018-09-26 00:00:00, 'SENTINEL2B_201809...   \n",
       "133098  {159: [2018-09-26 00:00:00, 'SENTINEL2B_201809...   \n",
       "133099  {159: [2018-09-26 00:00:00, 'SENTINEL2B_201809...   \n",
       "133100  {159: [2018-09-26 00:00:00, 'SENTINEL2B_201809...   \n",
       "133101  {159: [2018-09-26 00:00:00, 'SENTINEL2B_201809...   \n",
       "\n",
       "                                                     geom   type  \\\n",
       "0       POLYGON ((126000.000 6843000.000, 126000.000 6...  train   \n",
       "1       POLYGON ((126000.000 6843000.000, 126000.000 6...  train   \n",
       "2       POLYGON ((126000.000 6843000.000, 126000.000 6...  train   \n",
       "3       POLYGON ((126000.000 6843000.000, 126000.000 6...  train   \n",
       "4       POLYGON ((126000.000 6843000.000, 126000.000 6...  train   \n",
       "...                                                   ...    ...   \n",
       "133097  POLYGON ((399000.000 6831000.000, 399000.000 6...  train   \n",
       "133098  POLYGON ((399000.000 6831000.000, 399000.000 6...  train   \n",
       "133099  POLYGON ((399000.000 6831000.000, 399000.000 6...  train   \n",
       "133100  POLYGON ((399000.000 6831000.000, 399000.000 6...  train   \n",
       "133101  POLYGON ((399000.000 6831000.000, 399000.000 6...  train   \n",
       "\n",
       "                                          other_valid_acq  spot6_validity  \n",
       "0       {33: [2018-04-03 00:00:00, 'SENTINEL2A_2018040...           False  \n",
       "1       {33: [2018-04-03 00:00:00, 'SENTINEL2A_2018040...           False  \n",
       "2       {33: [2018-04-03 00:00:00, 'SENTINEL2A_2018040...           False  \n",
       "3       {33: [2018-04-03 00:00:00, 'SENTINEL2A_2018040...           False  \n",
       "4       {33: [2018-04-03 00:00:00, 'SENTINEL2A_2018040...           False  \n",
       "...                                                   ...             ...  \n",
       "133097  {159: [2018-09-26 00:00:00, 'SENTINEL2B_201809...            True  \n",
       "133098  {159: [2018-09-26 00:00:00, 'SENTINEL2B_201809...            True  \n",
       "133099  {159: [2018-09-26 00:00:00, 'SENTINEL2B_201809...            True  \n",
       "133100  {159: [2018-09-26 00:00:00, 'SENTINEL2B_201809...            True  \n",
       "133101  {159: [2018-09-26 00:00:00, 'SENTINEL2B_201809...           False  \n",
       "\n",
       "[133102 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "75*(10/1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
