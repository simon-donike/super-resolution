{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7aaff93-7ae4-492f-9482-dc28143627d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\accou\\anaconda3\\envs\\geo_env_n6\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import wandb\n",
    "#from prettytable import PrettyTable\n",
    "import random\n",
    "import os\n",
    "from datetime import datetime\n",
    "from torch.optim import lr_scheduler\n",
    "import pandas as pd\n",
    "from skimage import exposure\n",
    "\n",
    "# local imports\n",
    "from models_parameters import losses\n",
    "from utils import helper_functions\n",
    "from utils.dataloader import Dataset as dataset\n",
    "from utils.losses import calculate_metrics\n",
    "from utils.convert import convert_image\n",
    "import geopandas\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "779c8e69-fb6a-4e46-8c06-a11b8ad531e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "srcnn_checkpoint = \"model_files/srcnn_x4.pth\"\n",
    "rcan_checkpoint  = \"model_files/rcan_4x.pt\"\n",
    "srgan_checkpoint = \"model_files/srgan_4x.pth.tar\"\n",
    "srgan_temporal_checkpoint = \"model_files/srgan_4x_temporal.tar\"\n",
    "srgan_fusion_checkpoint = \"model_files/srgan_4x_fusion.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54b1c845-c43e-441a-a2b6-832a1cdb14f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataloader(dl_type=\"normal\",sen2_test_tile=\"all\"):\n",
    "    \n",
    "    working_directory = \"C:\\\\Users\\\\accou\\\\Documents\\\\GitHub\\\\a-PyTorch-Tutorial-to-Super-Resolution\\\\\"\n",
    "    folder_path = \"C:\\\\Users\\\\accou\\\\Documents\\\\thesis\\\\data_v2\\\\\"\n",
    "    dataset_file = \"C:\\\\Users\\\\accou\\\\Documents\\\\thesis\\\\data_v2\\\\final_dataset.pkl\"\n",
    "    \n",
    "    #filter_point=(367500.0,6822750.0) # Good one\n",
    "    #filter_point=(292500.0,6810750.0) # okay\n",
    "    #filter_point = (240750.0 , 6840000.0) # best one\n",
    "    filter_point=\"None\"\n",
    "\n",
    "    \n",
    "    if dl_type == \"normal\":\n",
    "        from utils.dataloader import Dataset as dataset\n",
    "        dataset_test   = dataset(folder_path,dataset_file,test_train_val=\"test\",transform=\"histogram_matching\",sen2_amount=1, sen2_tile = sen2_test_tile,   location=\"local\",filter_point=filter_point)\n",
    "        loader_test = DataLoader(dataset_test,batch_size=1, shuffle=False, num_workers=0,pin_memory=True,drop_last=False)\n",
    "    if dl_type == \"srcnn\":\n",
    "        from utils.dataloader_srcnn import Dataset as dataset\n",
    "        dataset_test   = dataset(folder_path,dataset_file,test_train_val=\"test\",transform=\"interpolate\",sen2_amount=1, sen2_tile = sen2_test_tile,   location=\"local\",filter_point=filter_point)\n",
    "        loader_test = DataLoader(dataset_test,batch_size=1, shuffle=False, num_workers=0,pin_memory=True,drop_last=False)\n",
    "    if dl_type == \"temporal\":\n",
    "        from utils.dataloader_temporal import Dataset as dataset\n",
    "        dataset_test   = dataset(folder_path,dataset_file,test_train_val=\"test\",transform=None,sen2_amount=4, sen2_tile = sen2_test_tile,   location=\"local\",filter_point=filter_point)\n",
    "        loader_test = DataLoader(dataset_test,batch_size=2, shuffle=False, num_workers=0,pin_memory=True,drop_last=False)\n",
    "    return loader_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6517750-af3c-47b7-b2da-1c1a80a041af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_SRCNN(checkpoint):\n",
    "    from torch import nn\n",
    "    class SRCNN(nn.Module):\n",
    "        def __init__(self, num_channels=1):\n",
    "            super(SRCNN, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(num_channels, 64, kernel_size=9, padding=9 // 2)\n",
    "            self.conv2 = nn.Conv2d(64, 32, kernel_size=5, padding=5 // 2)\n",
    "            self.conv3 = nn.Conv2d(32, num_channels, kernel_size=5, padding=5 // 2)\n",
    "            self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.relu(self.conv1(x))\n",
    "            x = self.relu(self.conv2(x))\n",
    "            x = self.conv3(x)\n",
    "            return x\n",
    "    model = SRCNN()\n",
    "    model.load_state_dict(torch.load(checkpoint))\n",
    "    #model = torch.load(checkpoint)\n",
    "    model = model.to(device)\n",
    "    model = model.eval()\n",
    "    return model\n",
    "\n",
    "def load_RCAN(checkpoint):\n",
    "    model = torch.load(checkpoint)\n",
    "    model = model.to(device)\n",
    "    model = model.eval()\n",
    "    return model\n",
    "\n",
    "def load_SRGAN(checkpoint):\n",
    "    model = torch.load(checkpoint)[\"generator\"]\n",
    "    model = model.to(device)\n",
    "    model = model.eval()\n",
    "    return(model)\n",
    "\n",
    "def load_SRGAN_fusion(checkpoint):\n",
    "    from models_fusion import Generator\n",
    "    # Generator parameters\n",
    "    large_kernel_size_g = 9  # kernel size of the first and last convolutions which transform the inputs and outputs\n",
    "    small_kernel_size_g = 3  # kernel size of all convolutions in-between, i.e. those in the residual and subpixel convolutional blocks\n",
    "    n_channels_g = 64  # number of channels in-between, i.e. the input and output channels for the residual and subpixel convolutional blocks\n",
    "    n_blocks_g = 16  # number of residual blocks\n",
    "    scaling_factor = 4\n",
    "    generator = Generator(large_kernel_size=large_kernel_size_g,\n",
    "                                  small_kernel_size=small_kernel_size_g,\n",
    "                                  n_channels=n_channels_g,\n",
    "                                  n_blocks=n_blocks_g,\n",
    "                                  scaling_factor=scaling_factor)\n",
    "\n",
    "    #generator = torch.load(checkpoint)[\"generator\"]\n",
    "    generator.load_state_dict(torch.load(checkpoint))\n",
    "    generator = model.to(device)\n",
    "    generator = model.eval()\n",
    "    return(generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3920dab8-8261-4a68-9642-b72dbc407259",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sr_srcnn(img):\n",
    "    model = model_SRCNN\n",
    "    img = img[0]\n",
    "    #img = img.numpy()\n",
    "    ls = []\n",
    "    for i in img:\n",
    "        ls.append(model(i.unsqueeze(0))[0])\n",
    "    r = torch.stack(ls)\n",
    "    return(r.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d03e1945-115c-4c07-b0fd-ce6ed07539ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_SRCNN = load_SRCNN(srcnn_checkpoint)\n",
    "model_RCAN  = load_RCAN(rcan_checkpoint)\n",
    "model_SRGAN = load_SRGAN(srgan_checkpoint)\n",
    "model_SRGAN_temporal = load_SRGAN(srgan_temporal_checkpoint)\n",
    "#model_SRGAN_fusion = load_SRGAN_fusion(srgan_fusion_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0cf9295-0fcc-4a56-ac01-762ddca9b040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Loader: 15894\n"
     ]
    }
   ],
   "source": [
    "loader_SRCNN = load_dataloader(\"srcnn\")\n",
    "loader_RCAN = load_dataloader(\"normal\")\n",
    "loader_SRGAN = load_dataloader(\"normal\")\n",
    "loader_SRGAN_temporal = load_dataloader(\"temporal\")\n",
    "print(\"Length of Loader:\",len(loader_SRCNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd269a5c-3274-4566-bb2e-5332cae7d415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model,dataloader):\n",
    "    def avg_ls(list):\n",
    "        return sum(lst) / len(lst)\n",
    "    \n",
    "    ls = []\n",
    "    metrics_list = []\n",
    "    count = 0\n",
    "    for lr,hr,coor in dataloader:\n",
    "        count=count+1\n",
    "        lr,hr = lr.to(device),hr.to(device)\n",
    "        sr = model(lr)\n",
    "        \n",
    "        \n",
    "        if lr.shape == torch.Size([2, 12, 75, 75]):\n",
    "            sr = sr[0].unsqueeze(0)\n",
    "            hr = hr[0].unsqueeze(0)\n",
    "            lr = lr[:,:3,::]\n",
    "            coor = coor[0]\n",
    "            \n",
    "        #print(lr.shape,hr.shape)\n",
    "            \n",
    "        metrics = calculate_metrics(hr,lr,sr)\n",
    "        # order: [lpips,psnr,ssim,mae,lpips_int,psnr_int,ssim_int,mae_int]\n",
    "        metrics_list.append(metrics)    \n",
    "        ls.append([coor[0].item(),coor[1].item(),metrics[0]])\n",
    "        \n",
    "        if count%100==0:\n",
    "            print(count,\"/\",len(dataloader),end=\"\\r\")\n",
    "    \n",
    "    df = pd.DataFrame(metrics_list,columns=[\"lpips\",\"psnr\",\"ssim\",\"mae\",\"lpips_int\",\"psnr_int\",\"ssim_int\",\"mae_int\"])\n",
    "    df = df.mean(axis=0).to_frame().transpose()\n",
    "    \n",
    "    print(\"one run finished\")\n",
    "    global res\n",
    "    res = ls\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a158b0-92b1-45d1-ab33-e98a1a8e29e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600 / 15894\r"
     ]
    }
   ],
   "source": [
    "\n",
    "# perform Test, get result DataFrame\n",
    "df = pd.concat([test_model(sr_srcnn,loader_SRCNN),test_model(model_RCAN,loader_RCAN),test_model(model_SRGAN,loader_SRGAN),test_model(model_SRGAN_temporal,loader_SRGAN_temporal)])\n",
    "df.index = [\"SRCNN\",\"RCAN\",\"SRGAN\",\"band stacking SRGAN\"]\n",
    "interpol = {\"lpips\":[df[\"lpips_int\"][0]],\"psnr\":[df[\"psnr_int\"][0]],\"ssim\":[df[\"ssim_int\"][0]],\"mae\":[df[\"mae_int\"][0]]}\n",
    "df.drop(labels=[\"lpips_int\",\"psnr_int\",\"ssim_int\",\"mae_int\"], axis=1,inplace=True)\n",
    "_ = pd.DataFrame.from_dict(interpol,orient='columns')\n",
    "_.index = index=[\"Bicubic Interpolation\"]\n",
    "df = pd.concat([df, _], ignore_index = False, axis = 0)\n",
    "\n",
    "# get heatmap of LPIPS\n",
    "heatmap = pd.DataFrame(res,columns=[\"x\",\"y\",\"lpips\"])\n",
    "heatmap = geopandas.GeoDataFrame(heatmap, geometry=geopandas.points_from_xy(heatmap.x, heatmap.y))\n",
    "heatmap = heatmap.set_crs('epsg:2154')\n",
    "\n",
    "# save results to disc\n",
    "df.to_pickle(\"result_comparison.pkl\")\n",
    "heatmap.to_pickle(\"heatmap.pkl\")\n",
    "heatmap.to_file(\"heatmap.geojson\", driver='GeoJSON')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e4fd50-7ec2-4510-8b7d-79f0df540b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435d17cd-c7de-4a2d-8051-94e675413aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d476e8c6-8cab-4622-b047-9967d5a8c113",
   "metadata": {},
   "outputs": [],
   "source": [
    "#heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b47e55-08b5-42ab-b262-1e92d0cb4dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#heatmap.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af4078e-efe9-4ba8-b4bc-20ffe3f16170",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "heatmap.plot(column='lpips', cmap='coolwarm', legend=True)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e5c4ae-c2b0-4951-b07d-8643ca6288f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#heatmap.to_file(\"heatmap.geojson\", driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405c9133-98ab-499a-b23d-20a6102bc8e1",
   "metadata": {},
   "source": [
    "# Produce Prediction Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3e24c2-ad68-4fd0-9561-643774b991e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.helper_functions import plot_tensors_window\n",
    "from utils.helper_functions import count_parameters\n",
    "import itertools\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e39cae-0d45-4ed8-bab3-b64a2899d64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_SRCNN = load_SRCNN(srcnn_checkpoint)\n",
    "model_RCAN  = load_RCAN(rcan_checkpoint)\n",
    "model_SRGAN = load_SRGAN(srgan_checkpoint)\n",
    "model_SRGAN_temporal = load_SRGAN(srgan_temporal_checkpoint)\n",
    "#model_SRGAN_fusion = load_SRGAN_fusion(srgan_fusion_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a961075-35cb-4955-9e92-9babcba4aa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_SRCNN = load_dataloader(\"srcnn\")\n",
    "loader_RCAN = load_dataloader(\"normal\")\n",
    "loader_SRGAN = load_dataloader(\"normal\")\n",
    "loader_SRGAN_temporal = load_dataloader(\"temporal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea709ce-f58e-4660-93a1-d357495390f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_images(model,loader,image_folder):\n",
    "    def avg_ls(list):\n",
    "        return sum(lst) / len(lst)\n",
    "    \n",
    "    \n",
    "    lr,hr,coor = next(itertools.islice(loader, 0, None)) # good: 250\n",
    "    \n",
    "    \n",
    "    ls = []\n",
    "    metrics_list = []\n",
    "    count = 0\n",
    "    \n",
    "    count=count+1\n",
    "    lr,hr = lr.to(device),hr.to(device)\n",
    "    sr = model(lr)\n",
    "    if image_folder==\"images_pred/SRGAN_bands\" or image_folder==\"images_pred/SRGAN\":\n",
    "        sr = convert_image(sr, source='[-1, 1]', target='imagenet-norm')\n",
    "    #metrics = calculate_metrics(hr,lr,sr)\n",
    "    metrics = [\"lpips\",\"psnr\",\"ssim\",\"mae\",\"lpips_int\",\"psnr_int\",\"ssim_int\",\"mae_int\"]\n",
    "    # order: [lpips,psnr,ssim,mae,lpips_int,psnr_int,ssim_int,mae_int]\n",
    "    metrics_list.append(metrics)    \n",
    "    #ls.append([coor[0].item(),coor[1].item(),metrics[0]])\n",
    "        \n",
    "    \n",
    "    if lr.shape!= torch.Size([1, 3, 300, 300]):\n",
    "        plot_tensors_window(hr,lr[:,:3,::],sr,fig_path=image_folder+\"/\")\n",
    "    else:\n",
    "        plot_tensors_window(hr,lr,sr,fig_path=image_folder+\"/\")\n",
    "        \n",
    "    #try:\n",
    "    #    count_parameters(model)\n",
    "    #except:\n",
    "    #    count_parameters(model_SRCNN)\n",
    "    \n",
    "    #df = pd.DataFrame(metrics_list,columns=[\"lpips\",\"psnr\",\"ssim\",\"mae\",\"lpips_int\",\"psnr_int\",\"ssim_int\",\"mae_int\"])\n",
    "    #df = df.mean(axis=0).to_frame().transpose()\n",
    "    \n",
    "    #res = ls\n",
    "    #return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ba4bbb-dfa1-4c56-b8c2-36c2fe4a2003",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SRCNN\")\n",
    "produce_images(sr_srcnn,loader_SRCNN,\"images_pred/SRCNN\")\n",
    "print(\"\\nRCAN\")\n",
    "produce_images(model_RCAN,loader_RCAN,\"images_pred/RCAN\")\n",
    "print(\"\\nSRGAN\")\n",
    "produce_images(model_SRGAN,loader_SRGAN,\"images_pred/SRGAN\")\n",
    "print(\"\\nSRGAN band stacking\")\n",
    "produce_images(model_SRGAN_temporal,loader_SRGAN_temporal,\"images_pred/SRGAN_bands\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884e94d5-8889-4e00-bfec-bd30e724b427",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for i in loader_SRGAN_temporal:\n",
    "    lr,hr,coor = i\n",
    "    hr,lr = hr.to(device),lr.to(device)\n",
    "    plot_tensors_window(hr,lr[:,:3,:,:],hr,fig_path=\"show\")\n",
    "    print(coor[0].item(),coor[1].item())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d13e782-65ae-4268-89c4-37c47b64b9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    working_directory = \"C:\\\\Users\\\\accou\\\\Documents\\\\GitHub\\\\a-PyTorch-Tutorial-to-Super-Resolution\\\\\"\n",
    "    folder_path = \"C:\\\\Users\\\\accou\\\\Documents\\\\thesis\\\\data_v2\\\\\"\n",
    "    dataset_file = \"C:\\\\Users\\\\accou\\\\Documents\\\\thesis\\\\data_v2\\\\final_dataset.pkl\"\n",
    "    \n",
    "\n",
    "    \n",
    "    from utils.dataloader_temporal import Dataset as dataset\n",
    "    dataset_test   = dataset(folder_path,dataset_file,test_train_val=\"test\",transform=None,sen2_amount=4, sen2_tile = all,   location=\"local\",filter_point=(367500.0,6822750.0))\n",
    "    loader_test = DataLoader(dataset_test,batch_size=1, shuffle=False, num_workers=0,pin_memory=True,drop_last=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df4b7dd-540a-4158-9679-4d7ee5000f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a = pd.read_pickle(\"C:\\\\Users\\\\accou\\\\Documents\\\\thesis\\\\data_v2\\\\final_dataset.pkl\")\n",
    "a = a[a[\"type\"]==\"test\"]\n",
    "#a = a[a[\"Code_simplified\"]==\"Agricultural Areas\"]\n",
    "a.reset_index(level=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a208fdf9-be2c-4c86-8921-cc3fec0757c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "no = 5200\n",
    "print(a.loc[no][\"x\"],\",\",a.loc[no][\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f29d7d-59f9-40ae-bfd5-6fb7c0562aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f14760e-cc27-4b25-817d-4bbedd7cca2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(loader_SRGAN_temporal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46637fd-dc8b-4dda-84a2-41a48389c153",
   "metadata": {},
   "outputs": [],
   "source": [
    " store_df[store_df['City'].isin(['New York', 'Los Angeles'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1779a3db-7cfa-45e1-b68a-b2b7dea11ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[a[\"Code_simplified\"].isin(['Wetlands', 'Agricultural Areas', 'Artificial Surfaces',\n",
    "       'Forest and seminatural Areas', 'Water Bodies'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879e5166-1781-4ac5-b20d-a0a032f5f839",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[\"Code_simplified\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044a0d66-50c3-4aaa-8588-ecf597e01f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_SRGAN_fusion = load_SRGAN_fusion(srgan_fusion_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e75a841-4bf8-4017-829c-b86d62e94b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_images_fusion(model,loader,image_folder):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "    \n",
    "    def avg_ls(list):\n",
    "        return sum(lst) / len(lst)\n",
    "    \n",
    "    \n",
    "    lr,hr,coor = next(itertools.islice(loader, 300, None)) # good: 250\n",
    "    \n",
    "    \n",
    "    ls = []\n",
    "    metrics_list = []\n",
    "    count = 0\n",
    "    \n",
    "    count=count+1\n",
    "    lr,hr = lr.to(device),hr.to(device)\n",
    "    sr = model(lr)\n",
    "    sr = sr.to(device)\n",
    "    sr = sr[0].unsqueeze(0)\n",
    "    hr = hr[0].unsqueeze(0)\n",
    "    coor = coor[0].unsqueeze(0)\n",
    "    metrics = calculate_metrics(hr,lr,sr) # [:,:3,:,:]\n",
    "    # order: [lpips,psnr,ssim,mae,lpips_int,psnr_int,ssim_int,mae_int]\n",
    "    metrics_list.append(metrics)    \n",
    "    ls.append([coor[0][0].item(),coor[0][1].item(),metrics[0]])\n",
    "        \n",
    "    \n",
    "    if lr.shape!= torch.Size([1, 3, 300, 300]):\n",
    "        plot_tensors_window(hr,lr[:,:3,::],sr,fig_path=image_folder+\"/\")\n",
    "    else:\n",
    "        plot_tensors_window(hr,lr,sr,fig_path=image_folder+\"/\")\n",
    "        \n",
    "    try:\n",
    "        count_parameters(model)\n",
    "    except:\n",
    "        count_parameters(model_SRCNN)\n",
    "    \n",
    "    df = pd.DataFrame(metrics_list,columns=[\"lpips\",\"psnr\",\"ssim\",\"mae\",\"lpips_int\",\"psnr_int\",\"ssim_int\",\"mae_int\"])\n",
    "    df = df.mean(axis=0).to_frame().transpose()\n",
    "    \n",
    "    res = ls\n",
    "    #return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaa1d69-1bac-4be6-8136-4298d1a0f7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSRGAN fusion\")\n",
    "produce_images(model_SRGAN_fusion,loader_SRGAN_temporal,\"images_pred/SRGAN_fusion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef8b2dd-23d3-4df2-8d56-24307b85d709",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
